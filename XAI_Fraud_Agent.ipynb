{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3de9146b",
   "metadata": {},
   "source": [
    "# XAI Fraud Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7846697",
   "metadata": {},
   "source": [
    "## Phase 1: The ML & Explainability Layer\n",
    "\n",
    "### Import Libraries for XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d19ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0a3958",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76bb803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_transaction(transaction_row, preprocessor=None):\n",
    "    \"\"\"\n",
    "    Helper function to preprocess a single transaction row.\n",
    "    Returns processed DataFrame.\n",
    "    \"\"\"\n",
    "    # Convert to DataFrame if it's a dict or Series\n",
    "    if not isinstance(transaction_row, pd.DataFrame):\n",
    "        df_input = pd.DataFrame([transaction_row])\n",
    "    else:\n",
    "        df_input = transaction_row.copy()\n",
    "        \n",
    "    # 1. Drop irrelevant columns\n",
    "    cols_to_drop = ['month', 'device_fraud_count', 'fraud_bool']\n",
    "    df_input = df_input.drop(columns=[c for c in cols_to_drop if c in df_input.columns], errors='ignore')\n",
    "    \n",
    "    # 2. Convert types\n",
    "    for col in df_input.columns:\n",
    "        if col not in ['payment_type', 'employment_status', 'housing_status', 'source', 'device_os']:\n",
    "             df_input[col] = pd.to_numeric(df_input[col], errors='coerce')\n",
    "                \n",
    "    # 3. Handle Missing Values\n",
    "    missing_cols = [\n",
    "        \"prev_address_months_count\", \"current_address_months_count\",\n",
    "        \"bank_months_count\", \"session_length_in_minutes\"\n",
    "    ]\n",
    "    for col in missing_cols:\n",
    "        if col in df_input.columns:\n",
    "             df_input[col] = df_input[col].replace(-1, np.nan)\n",
    "    \n",
    "    # 4. Apply OneHotEncoding\n",
    "    if preprocessor:\n",
    "        try:\n",
    "            X_transformed = preprocessor.transform(df_input)\n",
    "            return X_transformed\n",
    "        except Exception as e:\n",
    "            print(f\"Preprocessing error: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        return df_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6f2518",
   "metadata": {},
   "source": [
    "### Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd13354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(transaction_row, preprocessor, model_params_path='XGBoostModelParameters.json', model_path='XGBoostModel.json'):\n",
    "    \"\"\"\n",
    "    Takes a single transaction row, preprocesses it, and returns the fraud probability.\n",
    "    \"\"\"\n",
    "    # Load parameters\n",
    "    try:\n",
    "        with open(model_params_path, 'r') as file:\n",
    "            loaded_params = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {model_params_path} not found.\")\n",
    "        return None\n",
    "\n",
    "    X_transformed = preprocess_transaction(transaction_row, preprocessor)\n",
    "    if X_transformed is None:\n",
    "        return None\n",
    "    \n",
    "    X_numpy = X_transformed.to_numpy()\n",
    "\n",
    "    # Load Model (Note: This assumes model file exists)\n",
    "    try:\n",
    "        model = xgb.XGBClassifier(**loaded_params)\n",
    "        model.load_model(model_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Inference\n",
    "    try:\n",
    "        probability = model.predict_proba(X_numpy)[0, 1]\n",
    "        return float(probability)\n",
    "    except Exception as e:\n",
    "        print(f\"Prediction error: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8f239f",
   "metadata": {},
   "source": [
    "### Create SHAP Explanation Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f290ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shap_explanation(transaction_data, model, preprocessor):\n",
    "    \"\"\"\n",
    "    Generates a SHAP explanation for a single transaction.\n",
    "    Returns a dictionary with fraud probability and top 3 contributing features.\n",
    "    \"\"\"\n",
    "    # Preprocess\n",
    "    X_transformed = preprocess_transaction(transaction_data, preprocessor)\n",
    "    if X_transformed is None:\n",
    "        return {\"error\": \"Preprocessing failed\"}\n",
    "    \n",
    "    # Ensure we use DataFrame for column names in SHAP\n",
    "    feature_names = preprocessor.get_feature_names_out() if hasattr(preprocessor, 'get_feature_names_out') else X_transformed.columns\n",
    "    X_df = pd.DataFrame(X_transformed, columns=feature_names)\n",
    "    \n",
    "    # Calculate SHAP values\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer(X_df)\n",
    "    \n",
    "    # Get values for the first (and only) row\n",
    "    # shap_values.values shape is (1, n_features)\n",
    "    # Binary classification: some shap versions output values for both classes, some just one.\n",
    "    # For XGBClassifier binary, it usually outputs log-odds for class 1.\n",
    "    \n",
    "    row_values = shap_values.values[0]\n",
    "    # base_value = shap_values.base_values[0] # Not strictly needed for top 3\n",
    "    data_values = X_df.iloc[0]\n",
    "    \n",
    "    # Calculate probability\n",
    "    prob = model.predict_proba(X_df)[0, 1]\n",
    "    \n",
    "    # Identify top 3 features pushing score HIGHER (positive contribution to fraud class)\n",
    "    # We want features that increase the probability of fraud.\n",
    "    \n",
    "    # Create list of (feature_name, shap_value, feature_value)\n",
    "    contributions = []\n",
    "    \n",
    "    # Handle multi-class output shape if SHAP returns (1, n_features, 2)\n",
    "    if len(row_values.shape) > 1:\n",
    "        # Assuming class 1 is index 1\n",
    "        row_values = row_values[:, 1]\n",
    "\n",
    "    for name, val, feat_val in zip(X_df.columns, row_values, data_values):\n",
    "        contributions.append((name, val, feat_val))\n",
    "    \n",
    "    # Sort by SHAP value descending (highest positive impact first)\n",
    "    contributions.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    top_3 = contributions[:3]\n",
    "    \n",
    "    top_reasons = []\n",
    "    for name, val, feat_val in top_3:\n",
    "        # Clean up feature name (remove 'cat__' etc if present)\n",
    "        clean_name = str(name).replace('cat__', '').replace('remainder__', '')\n",
    "        \n",
    "        # Format based on value type\n",
    "        if isinstance(feat_val, (int, float)):\n",
    "             reason = f\"{clean_name} = {feat_val:.2f}\"\n",
    "        else:\n",
    "             reason = f\"{clean_name} = {feat_val}\"\n",
    "        \n",
    "        top_reasons.append(reason)\n",
    "        \n",
    "    return {\n",
    "        \"score\": float(prob),\n",
    "        \"top_reasons\": top_reasons\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2443c15c",
   "metadata": {},
   "source": [
    "## Phase 2: The Data Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2ef7f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       fraud_bool  income  name_email_similarity  prev_address_months_count  \\\n",
      "0               0     0.8               0.917751                         -1   \n",
      "1               0     0.7               0.671499                         63   \n",
      "2               0     0.9               0.856539                         -1   \n",
      "3               0     0.6               0.997083                        116   \n",
      "4               0     0.9               0.016758                         35   \n",
      "...           ...     ...                    ...                        ...   \n",
      "48417           0     0.4               0.448188                         -1   \n",
      "48418           0     0.9               0.728931                         26   \n",
      "48419           1     0.9               0.023149                         -1   \n",
      "48420           0     0.9               0.242042                         -1   \n",
      "48421           0     0.5               0.445138                         31   \n",
      "\n",
      "       current_address_months_count  customer_age  days_since_request  \\\n",
      "0                                28            40           15.880665   \n",
      "1                                 0            30            0.019754   \n",
      "2                                48            50            0.024904   \n",
      "3                                 8            40            0.016673   \n",
      "4                                13            40            0.036185   \n",
      "...                             ...           ...                 ...   \n",
      "48417                           136            40            0.011413   \n",
      "48418                            13            30            0.007199   \n",
      "48419                           225            30            0.003529   \n",
      "48420                           123            40            0.023383   \n",
      "48421                             0            30           20.524778   \n",
      "\n",
      "       intended_balcon_amount payment_type  zip_count_4w  ...  \\\n",
      "0                   -0.775614           AC           543  ...   \n",
      "1                   -1.201425           AC           320  ...   \n",
      "2                   -1.358778           AB          1300  ...   \n",
      "3                   40.940333           AA          1742  ...   \n",
      "4                   -1.222976           AB          1130  ...   \n",
      "...                       ...          ...           ...  ...   \n",
      "48417               -1.544081           AC           486  ...   \n",
      "48418               51.101624           AA           636  ...   \n",
      "48419               -1.153569           AB           386  ...   \n",
      "48420               -1.089033           AB          1403  ...   \n",
      "48421               -1.417292           AB          3063  ...   \n",
      "\n",
      "       has_other_cards  proposed_credit_limit  foreign_request    source  \\\n",
      "0                    0                  200.0                0  INTERNET   \n",
      "1                    0                  200.0                0  INTERNET   \n",
      "2                    0                  200.0                0  INTERNET   \n",
      "3                    0                  200.0                0  INTERNET   \n",
      "4                    1                  500.0                0  INTERNET   \n",
      "...                ...                    ...              ...       ...   \n",
      "48417                0                  200.0                0  INTERNET   \n",
      "48418                0                 1500.0                0  INTERNET   \n",
      "48419                0                  200.0                0  INTERNET   \n",
      "48420                1                  200.0                0  INTERNET   \n",
      "48421                0                  200.0                0  INTERNET   \n",
      "\n",
      "       session_length_in_minutes  device_os  keep_alive_session  \\\n",
      "0                      10.687497      other                   0   \n",
      "1                       2.772922      other                   0   \n",
      "2                       2.784509    windows                   1   \n",
      "3                      11.529431      linux                   1   \n",
      "4                       8.016704    windows                   0   \n",
      "...                          ...        ...                 ...   \n",
      "48417                   0.165385      linux                   1   \n",
      "48418                   0.870677      linux                   0   \n",
      "48419                  13.643385      linux                   1   \n",
      "48420                   4.410169    windows                   1   \n",
      "48421                  11.349303  macintosh                   0   \n",
      "\n",
      "       device_distinct_emails_8w device_fraud_count    user_id  \n",
      "0                              1                  0  USER_0000  \n",
      "1                              1                  0  USER_0001  \n",
      "2                              1                  0  USER_0002  \n",
      "3                              1                  0  USER_0003  \n",
      "4                              1                  0  USER_0004  \n",
      "...                          ...                ...        ...  \n",
      "48417                          1                  0  USER_0001  \n",
      "48418                          1                  0  USER_0002  \n",
      "48419                          1                  0  USER_0003  \n",
      "48420                          1                  0  USER_0004  \n",
      "48421                          1                  0  USER_0005  \n",
      "\n",
      "[48422 rows x 32 columns]\n",
      "\n",
      "Data read from SQLite table:\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import kagglehub\n",
    "from faker import Faker\n",
    "\n",
    "# Setup SQLLite connection \n",
    "connection = sqlite3.connect(\"Fraud_Agent.db\")\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"sgpjesus/bank-account-fraud-dataset-neurips-2022\")\n",
    "\n",
    "#print(\"Path to dataset files:\", path)\n",
    "# ensure we point to a .csv file (dataset_download may return a path without extension)\n",
    "csv_path = str(path) + \"/Base.csv\"\n",
    "\n",
    "# read the CSV into a DataFrame and setup the final test data\n",
    "df_OG = pd.read_csv(csv_path)\n",
    "mask = df_OG[\"month\"] == 7\n",
    "\n",
    "full_test_data = df_OG[mask].sample(frac=0.5).reset_index(drop=True).drop('month',axis=1) \n",
    "\n",
    "df = full_test_data\n",
    "\n",
    "# Add \n",
    "fake = Faker()\n",
    "num_users = len(df) // 8\n",
    "user_ids = [f\"USER_{i:04d}\" for i in range(num_users)]\n",
    "\n",
    "df['user_id'] = (user_ids * 9)[:len(df)]\n",
    "\n",
    "print(df)\n",
    "\n",
    "# Setup a Table in SQL\n",
    "table_name = \"transaction_history\"\n",
    "full_test_data.to_sql(table_name, connection, if_exists='replace', index=False)\n",
    "\n",
    "# Verify the data was written by reading it back into a new DataFrame\n",
    "query = f\"SELECT * FROM {table_name}\"\n",
    "result_df = pd.read_sql_query(query, connection)\n",
    "print(\"\\nData read from SQLite table:\")\n",
    "#print(result_df)\n",
    "\n",
    "# Close the database connection\n",
    "connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74799e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the database is: 13254656 bytes (via PRAGMA)\n"
     ]
    }
   ],
   "source": [
    "def get_db_size_pragma(db_path):\n",
    "    \"\"\"\n",
    "    Gets the size of a SQLite database in bytes using PRAGMA statements.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Get page count\n",
    "    cursor.execute(\"PRAGMA page_count;\")\n",
    "    page_count = cursor.fetchone()[0]\n",
    "\n",
    "    # Get page size\n",
    "    cursor.execute(\"PRAGMA page_size;\")\n",
    "    page_size = cursor.fetchone()[0]\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    # Calculate total size in bytes\n",
    "    size_in_bytes = page_count * page_size\n",
    "    return size_in_bytes\n",
    "\n",
    "db_file_path = \"Fraud_Agent.db\"\n",
    "size = get_db_size_pragma(db_file_path)\n",
    "\n",
    "print(f\"The size of the database is: {size} bytes (via PRAGMA)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89175624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.remove(\"Fraud_Agent.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c920822",
   "metadata": {},
   "source": [
    "### The Vector Store. \n",
    "Write a script to read that PDF, split it into chunks using LangChain's RecursiveCharacterTextSplitter, and save it into a local ChromaDB vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fa5a430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Fraud_Detection_Policy.pdf...\n",
      "Splitting text...\n",
      "Created 3 chunks.\n",
      "Initializing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 1504.80it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ChromaDB client...\n",
      "Adding documents to collection 'bank_policies'...\n",
      "Successfully added 3 chunks to ChromaDB at ./chroma_db\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import chromadb\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Fix for SQLite on Mac (common issue with ChromaDB)\n",
    "import sqlite3\n",
    "import sys\n",
    "if sys.platform.startswith('darwin'):\n",
    "    try:\n",
    "        __import__('pysqlite3')\n",
    "        sys.modules['sqlite3'] = sys.modules['pysqlite3']\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "# Configuration\n",
    "CHROMA_PATH = \"./chroma_db\"\n",
    "CHROMA_COLLECTION_NAME = \"bank_policies\"\n",
    "PDF_PATH = \"Fraud_Detection_Policy.pdf\"\n",
    "\n",
    "def ingest_pdf():\n",
    "    # 1. Load PDF\n",
    "    if not os.path.exists(PDF_PATH):\n",
    "        print(f\"Error: {PDF_PATH} not found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loading {PDF_PATH}...\")\n",
    "    loader = PyPDFLoader(PDF_PATH)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # 2. Split Text\n",
    "    print(\"Splitting text...\")\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    chunked_documents = text_splitter.split_documents(documents)\n",
    "    \n",
    "    print(f\"Created {len(chunked_documents)} chunks.\")\n",
    "\n",
    "    # 3. Initialize Embeddings\n",
    "    print(\"Initializing embeddings...\")\n",
    "    embedding_function = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    # 4. Initialize Chroma Client\n",
    "    print(\"Initializing ChromaDB client...\")\n",
    "    chroma_client = chromadb.PersistentClient(path=CHROMA_PATH)\n",
    "\n",
    "    # 5. Add to Chroma\n",
    "    print(f\"Adding documents to collection '{CHROMA_COLLECTION_NAME}'...\")\n",
    "    Chroma.from_documents(\n",
    "        documents=chunked_documents,\n",
    "        embedding=embedding_function,\n",
    "        collection_name=CHROMA_COLLECTION_NAME,\n",
    "        client=chroma_client,\n",
    "    )\n",
    "    \n",
    "    print(f\"Successfully added {len(chunked_documents)} chunks to ChromaDB at {CHROMA_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ingest_pdf()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02529dc",
   "metadata": {},
   "source": [
    "## Building the Agent's \"Tools\" \n",
    "Step 3.1: Database Tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b951fd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_user_transactions(user_id: str):\n",
    "    \"\"\"\n",
    "    Randomly select 5 transactions for this user.\n",
    "    Use this tool when you need to verify if a user has a history of fraud\n",
    "    transactions.\n",
    "    \"\"\"\n",
    "    db_path = \"Fraud_Agent.db\"\n",
    "\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # SELECT any 5 transactions of the user at random\n",
    "    query = f\"SELECT * FROM transaction_history WHERE user_id = '{user_id}' LIMIT 5\"\n",
    "    result_df = pd.read_sql_query(query, conn)\n",
    "    print(\"\\nData read from SQLite table:\")\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f53859",
   "metadata": {},
   "source": [
    "## Policy RAG Tool\n",
    "Write a function search_bank_policy(query: str) that queries your ChromaDB and returns the most relevant paragraph from your PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfdfbdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 1630.89it/s, Materializing param=pooler.dense.weight]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Found: Housing Status (BE, BB, BC): These anonymized categories are historically associated with lower\n",
      "fraud rates.\n",
      "Escalation Rules\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from transformers import logging as transformers_logging\n",
    "transformers_logging.set_verbosity_error()\n",
    "logging.getLogger(\"huggingface_hub\").setLevel(logging.ERROR)\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.tools import tool\n",
    "import chromadb\n",
    "import sys\n",
    "\n",
    "# Fix for SQLite on Mac (common issue with ChromaDB)\n",
    "if sys.platform.startswith('darwin'):\n",
    "    try:\n",
    "        __import__('pysqlite3')\n",
    "        sys.modules['sqlite3'] = sys.modules['pysqlite3']\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "CHROMA_PATH = \"./chroma_db\"\n",
    "CHROMA_COLLECTION_NAME = \"bank_policies\"\n",
    "\n",
    "@tool\n",
    "def search_bank_policy(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Searches the official Bank Anti-Fraud Policy documentation. \n",
    "    Use this tool when you need to verify if a flagged transaction \n",
    "    violates specific banking regulations or internal risk thresholds.\n",
    "    \"\"\"\n",
    "    # Consistency: Use same embeddings and paths as ingestion\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    # Initialize Persistent Client\n",
    "    chroma_client = chromadb.PersistentClient(path=CHROMA_PATH)\n",
    "\n",
    "    vector_db = Chroma(\n",
    "        client=chroma_client,\n",
    "        embedding_function=embeddings,\n",
    "        collection_name=CHROMA_COLLECTION_NAME\n",
    "    )\n",
    "    \n",
    "    # Perform the Similarity Search\n",
    "    # k=1 returns only the single most relevant paragraph\n",
    "    docs = vector_db.similarity_search(query, k=1)\n",
    "    \n",
    "    if not docs:\n",
    "        return \"No relevant policy found for this query.\"\n",
    "    \n",
    "    # Return the text content of the best match\n",
    "    return docs[0].page_content\n",
    "\n",
    "# Test the tool manually\n",
    "try:\n",
    "    # result = search_bank_policy.invoke(\"What is the limit for overseas wire transfers?\")\n",
    "    result = search_bank_policy.invoke(\"housing status\")\n",
    "    print(f\"Policy Found: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during search: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9489bc0",
   "metadata": {},
   "source": [
    "### Testing tools and functions\n",
    "Please comment out @tools from above functions to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71ddd8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EEEE\n",
      "======================================================================\n",
      "ERROR: test_get_user_transactions_output_type (__main__.TestCoreTools.test_get_user_transactions_output_type)\n",
      "Verify that get_user_transactions returns a pandas DataFrame.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/j_/r592xntd31b897xl6vt_hhl00000gn/T/ipykernel_52199/3919581003.py\", line 23, in test_get_user_transactions_output_type\n",
      "    df = get_user_transactions(\"USER_0000\")\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: 'StructuredTool' object is not callable\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_get_user_transactions_valid_user (__main__.TestCoreTools.test_get_user_transactions_valid_user)\n",
      "Verify that get_user_transactions returns data for a valid user.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/j_/r592xntd31b897xl6vt_hhl00000gn/T/ipykernel_52199/3919581003.py\", line 32, in test_get_user_transactions_valid_user\n",
      "    df = get_user_transactions(\"USER_0000\")\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: 'StructuredTool' object is not callable\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_search_bank_policy_content (__main__.TestCoreTools.test_search_bank_policy_content)\n",
      "Verify that search_bank_policy returns relevant content.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/j_/r592xntd31b897xl6vt_hhl00000gn/T/ipykernel_52199/3919581003.py\", line 54, in test_search_bank_policy_content\n",
      "    result = search_bank_policy(\"risk indicators\")\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: 'StructuredTool' object is not callable\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_search_bank_policy_output_type (__main__.TestCoreTools.test_search_bank_policy_output_type)\n",
      "Verify that search_bank_policy returns a string.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/j_/r592xntd31b897xl6vt_hhl00000gn/T/ipykernel_52199/3919581003.py\", line 44, in test_search_bank_policy_output_type\n",
      "    result = search_bank_policy(\"housing status\")\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: 'StructuredTool' object is not callable\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.002s\n",
      "\n",
      "FAILED (errors=4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x12c926f90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "from transformers import logging as transformers_logging\n",
    "transformers_logging.set_verbosity_error()\n",
    "logging.getLogger(\"huggingface_hub\").setLevel(logging.ERROR)\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "import unittest\n",
    "\n",
    "# Fix for SQLite on Mac (common issue with ChromaDB)\n",
    "if sys.platform.startswith('darwin'):\n",
    "    try:\n",
    "        __import__('pysqlite3')\n",
    "        sys.modules['sqlite3'] = sys.modules['pysqlite3']\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "# --- Unit Tests ---\n",
    "class TestCoreTools(unittest.TestCase):\n",
    "    \n",
    "    def test_get_user_transactions_output_type(self):\n",
    "        \"\"\"Verify that get_user_transactions returns a pandas DataFrame.\"\"\"\n",
    "        # Using a sample user ID from the database\n",
    "        df = get_user_transactions(\"USER_0000\")\n",
    "        if df is not None:\n",
    "            self.assertIsInstance(df, pd.DataFrame)\n",
    "            print(\"\\n[PASSED] get_user_transactions returns a DataFrame.\")\n",
    "        else:\n",
    "            self.skipTest(\"Fraud_Agent.db not found for integration test.\")\n",
    "\n",
    "    def test_get_user_transactions_valid_user(self):\n",
    "        \"\"\"Verify that get_user_transactions returns data for a valid user.\"\"\"\n",
    "        df = get_user_transactions(\"USER_0000\")\n",
    "        if df is not None:\n",
    "            # We know USER_0000 exists if the database was setup correctly\n",
    "            # If the DB is empty, this might be 0, but it should still be a DF\n",
    "            self.assertTrue(len(df) >= 0)\n",
    "            print(f\"[PASSED] get_user_transactions returned {len(df)} rows for USER_0000.\")\n",
    "        else:\n",
    "            self.skipTest(\"Fraud_Agent.db not found for integration test.\")\n",
    "\n",
    "    def test_search_bank_policy_output_type(self):\n",
    "        \"\"\"Verify that search_bank_policy returns a string.\"\"\"\n",
    "        if os.path.exists(\"./chroma_db\"):\n",
    "            result = search_bank_policy(\"housing status\")\n",
    "            self.assertIsInstance(result, str)\n",
    "            self.assertNotEqual(result, \"No relevant policy found for this query.\")\n",
    "            print(\"[PASSED] search_bank_policy returns a valid string.\")\n",
    "        else:\n",
    "            self.skipTest(\"./chroma_db not found for integration test.\")\n",
    "\n",
    "    def test_search_bank_policy_content(self):\n",
    "        \"\"\"Verify that search_bank_policy returns relevant content.\"\"\"\n",
    "        if os.path.exists(\"./chroma_db\"):\n",
    "            result = search_bank_policy(\"risk indicators\")\n",
    "            self.assertTrue(len(result) > 10)\n",
    "            print(f\"[PASSED] search_bank_policy returned relevant content: {result[:50]}...\")\n",
    "        else:\n",
    "            self.skipTest(\"./chroma_db not found for integration test.\")\n",
    "\n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58710ff0",
   "metadata": {},
   "source": [
    "## Phase 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "shap_agent_bridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saimzafar2002-apple.com/venvs/python_3_12/lib/python3.12/site-packages/sklearn/base.py:463: InconsistentVersionWarning: Trying to unpickle estimator OneHotEncoder from version 1.7.2 when using version 1.8.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/saimzafar2002-apple.com/venvs/python_3_12/lib/python3.12/site-packages/sklearn/base.py:463: InconsistentVersionWarning: Trying to unpickle estimator FunctionTransformer from version 1.7.2 when using version 1.8.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/saimzafar2002-apple.com/venvs/python_3_12/lib/python3.12/site-packages/sklearn/base.py:463: InconsistentVersionWarning: Trying to unpickle estimator ColumnTransformer from version 1.7.2 when using version 1.8.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud Score: 0.09384600818157196\n",
      "Top Reasons: ['payment_type_AC = 1.00', 'velocity_4w = 3158.28', 'bank_branch_count_8w = 0.00']\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import xgboost as xgb\n",
    "\n",
    "# 1. Load Preprocessor and Model\n",
    "preprocessor = joblib.load('preprocessor.joblib')\n",
    "model = xgb.XGBClassifier()\n",
    "model.load_model('XGBoostModel.json')\n",
    "\n",
    "# 2. Get a sample high-risk transaction\n",
    "# We'll use a sample from the dataframe created in Phase 2\n",
    "sample_row = df.iloc[0].to_dict()\n",
    "\n",
    "# 3. Generate SHAP explanation\n",
    "explanation = get_shap_explanation(sample_row, model, preprocessor)\n",
    "print(f\"Fraud Score: {explanation['score']}\")\n",
    "print(f\"Top Reasons: {explanation['top_reasons']}\")\n",
    "\n",
    "# 4. Store user_id for the agent\n",
    "investigated_user_id = sample_row.get('user_id', 'USER_0000')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2b5306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -qU langchain-google-genai langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09f4b2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyC3oAFLC1AvkrhWvSwmxuIsY_7bgT8XBY0\n",
      "\n",
      "Data read from SQLite table:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 1291.04it/s, Materializing param=pooler.dense.weight]                             \n",
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 1214.77it/s, Materializing param=pooler.dense.weight]                             \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"\\nInvestigate transaction for USER_0000.\\nModel Fraud Probability: 0.09\\nTop SHAP Contributing Factors:\\n- payment_type_AC = 1.00\\n- velocity_4w = 3158.28\\n- bank_branch_count_8w = 0.00\\n\\nPlease check the user's transaction history and cross-reference with bank policy to generate a final memo.\\n\", additional_kwargs={}, response_metadata={}, id='af124f9b-aa1a-4db9-87d0-c86208e4ba5a'),\n",
       "  AIMessage(content=[], additional_kwargs={'function_call': {'name': 'get_user_transactions', 'arguments': '{\"user_id\": \"USER_0000\"}'}, '__gemini_function_call_thought_signatures__': {'375c97be-88da-4a01-ab5c-e41a88b61292': 'EtAECs0EAb4+9vuOyNXAsjs+eXaW7PIVCznuCi/0CidzQ5fBj+6bafawZXpwWHNGh3oMkSK5YUNCPbczJSg31A2zSTvFJEr6fZyKhdewooRfph0FMq0EhjT3L//ZKL2t9A+spTRQBifrSeLa72TER0z10PgtieZnomybsuWIedrubJjAdB7WnrXwnKIYZLxSobvzC12QtlUiV7AEaK5SmKd5gre7FPdVrcRB773nFcqAEvkcy3tIsYNgchwvH9ZMPzbgCAuvFR8KarH61vdGbJcZcuf3uMyeAki2AYM8AxnDeVD3r4AEt9fw2aXVfGCt8LgjM9QEKqyic+cz/HQK5FP4Y+EpUDYUqur2pWuBljueD14V0nAI1OcrH40PKasUXUJDBkPZ+bCRQwAxwor8EW/Q9OH926ZpGHgaoNS6tRfu1Xnjv0Wfx9K8R4QDmNSyPXO46BI3gAr30okdmYJz0gvt9srbbPlV79nWEAcI1ysuADXoqHdNZSVCf088RyLtqxiB36wpk1xD0r3KUwJ9LFY9n0Z66EXtXFFjtA3cYml7bxRibOgKKtY2uKjumbnL3ZDZW9aZHem2IFqbqRfhPG63zzrdC67RbnTwGq6QD1CHRGhrFdtPKYkm9rnLhQLSBa9JzEuZSgmMIMAbUp2iC2YgiKbMNnntgKYbmXZ3SyWuJlvrbdPXjskpc3gA/cLhad2WDvLRgUQ2F+EE9ckhYvn1T0L2Q5wiwHi7ned8xm7cqqDp0MG/2wVTWRrXZDW45op7joz1KkTsE5fZ3UwSfDzz/g=='}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-3-flash-preview', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c86bb-ee14-7540-abe0-9023532ad0fb-0', tool_calls=[{'name': 'get_user_transactions', 'args': {'user_id': 'USER_0000'}, 'id': '375c97be-88da-4a01-ab5c-e41a88b61292', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 299, 'output_tokens': 213, 'total_tokens': 512, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 188}}),\n",
       "  ToolMessage(content='   fraud_bool  income  name_email_similarity  prev_address_months_count  \\\\\\n0           0     0.8               0.917751                         -1   \\n1           0     0.1               0.693122                         30   \\n2           0     0.5               0.351529                         -1   \\n3           0     0.4               0.157462                         -1   \\n4           0     0.8               0.274556                         30   \\n\\n   current_address_months_count  customer_age  days_since_request  \\\\\\n0                            28            40           15.880665   \\n1                             4            50            0.008996   \\n2                            24            20            0.001365   \\n3                            24            20            0.013896   \\n4                            18            20            0.020841   \\n\\n   intended_balcon_amount payment_type  zip_count_4w  ...  has_other_cards  \\\\\\n0               -0.775614           AC           543  ...                0   \\n1               23.212937           AA          1800  ...                1   \\n2               50.141388           AA           304  ...                1   \\n3               23.798581           AA           919  ...                0   \\n4               27.001374           AA           490  ...                0   \\n\\n   proposed_credit_limit  foreign_request    source  \\\\\\n0                  200.0                0  INTERNET   \\n1                 1000.0                0  INTERNET   \\n2                  200.0                0  INTERNET   \\n3                  200.0                0  INTERNET   \\n4                  500.0                0  INTERNET   \\n\\n   session_length_in_minutes device_os  keep_alive_session  \\\\\\n0                  10.687497     other                   0   \\n1                   4.207399     linux                   0   \\n2                   2.530333     other                   0   \\n3                   4.390247     other                   1   \\n4                   1.784766     linux                   1   \\n\\n   device_distinct_emails_8w device_fraud_count    user_id  \\n0                          1                  0  USER_0000  \\n1                          2                  0  USER_0000  \\n2                          1                  0  USER_0000  \\n3                          1                  0  USER_0000  \\n4                          1                  0  USER_0000  \\n\\n[5 rows x 32 columns]', name='get_user_transactions', id='fecb6b9e-23a9-49ea-a149-9c2ab221df68', tool_call_id='375c97be-88da-4a01-ab5c-e41a88b61292'),\n",
       "  AIMessage(content=[], additional_kwargs={'function_call': {'name': 'search_bank_policy', 'arguments': '{\"query\": \"payment_type_AC velocity_4w bank_branch_count_8w\"}'}, '__gemini_function_call_thought_signatures__': {'4a9e6fd0-d63e-4042-b956-ed9a763962ee': 'EoQDCoEDAb4+9vtUjOcP5z7XF5z5Y+5gMalEMoMGNcQnqBSJWkovVTFJVMNkOBYv1yCahbS66Cvu+GtAB9ri13h1D0zFTiG6CEaMy/RQ/7qMb8DsSa82DcGmb7UlughbQBX1Yap1vKpvik5ysGAjk5iFP3yurqiok5/nkj+xY1CBbIqTkulgq5qRcdt9orl44473okllW4qQ+yOZ1+tE7sCQ+IY6D0fqc62/NOcCZqGfNJcaUaGx543ji+09LXAo6Awkjd1c4i8FUIcFLlnwI9nH4nMG8fcMnmOECJJ7C21Dq51N0IMh9c3bpg6GAMRXxyXkUSD8Ux+eic/FTuGZWTijOgw2fwXtfbIFDYp2ygARNKEIq7g0pZ9BAb/VSL9oi5rBP8/otfKXQcf7IogXeB5VwM+Fz8ATLfh32d15myxNS9Sp8QoukOiy571flCUTk4fi8taYyWKxMQKXA0Tm9xSuC9m10Q8bTpQtu37Wv9JRFqC5r8wsk5GttEV5Sk/llArxGNq/ig=='}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-3-flash-preview', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c86bb-f729-7761-9e63-1f7adfb686fd-0', tool_calls=[{'name': 'search_bank_policy', 'args': {'query': 'payment_type_AC velocity_4w bank_branch_count_8w'}, 'id': '4a9e6fd0-d63e-4042-b956-ed9a763962ee', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 1196, 'output_tokens': 141, 'total_tokens': 1337, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 107}}),\n",
       "  ToolMessage(content='Manual review is required if: \\x7f Missing previous address duration AND Windows OS \\x7f Missing previous\\naddress duration with no negative signals \\x7f Two or more strong positive indicators Auto-approval may\\nproceed if: \\x7f No positive signals and at least two strong negative signals \\x7f Existing validated customer\\nwith strong identity indicators\\nGovernance and Monitoring\\n\\x7f Risk thresholds reviewed quarterly \\x7f Model drift and bias monitoring conducted regularly \\x7f Signals\\ntreated as probabilistic, not deterministic proof of fraud\\nRisk Impact Summary\\nSignal\\nDirection\\nStrength\\nMissing Previous Address\\nIncrease Risk\\nStrong\\nWindows OS\\nIncrease Risk\\nModerate\\nSession Persistence\\nReduce Risk\\nModerate\\nName–Email Similarity\\nReduce Risk\\nModerate\\nValid Home Phone\\nReduce Risk\\nModerate\\nExisting Cards with Bank\\nReduce Risk\\nStrong\\nHousing Status BE/BB/BC\\nReduce Risk\\nLow–Moderate', name='search_bank_policy', id='36ffb479-44e6-44bd-8d6d-62e0e5793b2a', tool_call_id='4a9e6fd0-d63e-4042-b956-ed9a763962ee'),\n",
       "  AIMessage(content=[], additional_kwargs={'function_call': {'name': 'search_bank_policy', 'arguments': '{\"query\": \"velocity_4w payment_type_AC bank_branch_count_8w thresholds\"}'}, '__gemini_function_call_thought_signatures__': {'11d9d5d2-a192-4fdc-aac3-ab1d505f8e3e': 'Eq4CCqsCAb4+9vv4jztjDAsMdgzDNY5sCwGSFjoSKxKDNFxCdA2qYzLO2hjesDdTBANd7BiJWX6IXdFdW+10+kOzRinyelgdV2/mpVlUKtOwUGGjgeKrrMuIUrHdUIEZIRifDXhsVo2zvrXXRi9LMCsoXGsZ59B2QPIK8CUzzavXiwRGFJ0g/G3wWpd498aB81w7rke5yTs1qTWnivUruJYSjQiEca0efBXKw9vHgYnytT+0KX92YPsHHe4xBRTrQSNNjtE+AyT5L4jPmctaYhCp4K0sSklJ51cQ7pTmDtP5tuLGDFuhTaZVzDr92t30UEL0F9gFIDO6fttq2efwCxVt0jq+vRTktzeY6MmX4qfnOJFZXixKT+//Rwibh9FcRiR6rL/qmfRgkN9dCm+7fjU='}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-3-flash-preview', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c86bc-0b5a-72f1-a3c8-c17da11d5843-0', tool_calls=[{'name': 'search_bank_policy', 'args': {'query': 'velocity_4w payment_type_AC bank_branch_count_8w thresholds'}, 'id': '11d9d5d2-a192-4fdc-aac3-ab1d505f8e3e', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 1527, 'output_tokens': 103, 'total_tokens': 1630, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 68}}),\n",
       "  ToolMessage(content='Manual review is required if: \\x7f Missing previous address duration AND Windows OS \\x7f Missing previous\\naddress duration with no negative signals \\x7f Two or more strong positive indicators Auto-approval may\\nproceed if: \\x7f No positive signals and at least two strong negative signals \\x7f Existing validated customer\\nwith strong identity indicators\\nGovernance and Monitoring\\n\\x7f Risk thresholds reviewed quarterly \\x7f Model drift and bias monitoring conducted regularly \\x7f Signals\\ntreated as probabilistic, not deterministic proof of fraud\\nRisk Impact Summary\\nSignal\\nDirection\\nStrength\\nMissing Previous Address\\nIncrease Risk\\nStrong\\nWindows OS\\nIncrease Risk\\nModerate\\nSession Persistence\\nReduce Risk\\nModerate\\nName–Email Similarity\\nReduce Risk\\nModerate\\nValid Home Phone\\nReduce Risk\\nModerate\\nExisting Cards with Bank\\nReduce Risk\\nStrong\\nHousing Status BE/BB/BC\\nReduce Risk\\nLow–Moderate', name='search_bank_policy', id='886f110a-3366-4218-a8b1-6f824782d137', tool_call_id='11d9d5d2-a192-4fdc-aac3-ab1d505f8e3e'),\n",
       "  AIMessage(content=[{'type': 'text', 'text': \"The transaction for USER_0000 is classified as legitimate, supported by a low model fraud probability of 0.09 and a consistent history of five non-fraudulent transactions. Although the velocity_4w is high, the user has previously utilized the AC payment type without issue, aligning with bank policy that favors auto-approval for established customers with strong identity indicators. Consequently, the flagged factors are considered characteristic of the user's normal banking behavior rather than indicative of fraudulent activity.\", 'extras': {'signature': 'Ep8LCpwLAb4+9vulXa5VU6ARVZFpiidjKOLGdFin1dDaDW6I/B5woX1l4+3oA5KBIi7Mf3NPLHZkXxlOkFdAht4gFgq8hsLtPysOcDQ1vXVZCKMMqqc1TFUBA1pk2g3vN6/idnthQysrK3d9DDsAeISOPTWmbb8wo1hixOhRep/JBH52lz/eyVNcLzm2OnXHsXtplRJGx0Czux0VXmISWmQfepVINW5vvoTIBkRMKXm8z+zRWoCs1UJww7sdPChlLbn0JxkLjxtY2jnZrlYoZYIoDFZVvweXJ+D+KpYFcdMdGXOZ5sVCM8s7iDJI97Z5OZ1oTfiTo+VzENFeevGQS5LDvCAV2zVgujgY5ckAdIHPQS9agyB7LqEeUhbvilalPPzJolHdxl0jEi2spzSa4O1VaCrTr0ujhTsPqLmfB9WNKMobRJ0a0Ekdu+2fpI4BL+DU+Ux+uuD6spmNvoAJ1a9mjVvSr7vdPUgMBaVMSZXIZt4NRpyvvsW2z+HvQobRb64O7DaUiRUvfpdqnm80zlg/QbD2/5Su8qKOkEwFPXiNfkSHDX8t7gc8QAKatos0GKNF8d1ybJCY+0effEtlQ8v3oUk5LxZJ81cVQm/0/RgTcS3lUYfc4/Bava1MKbXzvjCVRTvLDWyTqvGZ2Jocwa4T6+Zl66EsmQzafxMMBb0TxlEME9IS5dNSxfhOK7YkBE99yV3QyHIBsLwLjcSa+CKBV1qrYxCd6W/c+En3wiM4ya4+zDrcAAGjdJkvlXuongVZA8Xl9Ca24ptFi+DTgH4qHiyQd+Sn3yLgVeUHmnj3XEsJ1M3g3NfNxGaLNG9lj77RNA0IOW8+Bj5HzxqEdkU5sdNFq4qQzErJQQ0mG4R85e2EABPTu4fPRegVHz7JW56VYmLYn3Y//l/Gxq42TJAM89g+HLE0DFt+NPGY16CYtmyaJ96OGpNmhtYmEpKBGkQYJZGyxq9rsaGLXZHbmcl6z/mcJ6+xsM1aYuzerOYjI4QOItbh+AzPbHpM6ofHQ3B5DZGk3QLhN+NXl4KeoiEwRzpvcPM7vl4P4ZXsFKXvtB0i8ydffixL5v3TFOdbmPL7SsDA/MMFWWPRbgs8K8Eiw2stzPPNIdH5YtqO82MivUnbn4QuTZQkhCCbejI+Hp4ds5AG7eziBUG+B3XDbDwgCctlLa3cMzWUa9UleTFO77WCY110nCOjs0zHixYy5p2LdoyZhCUbxHFlBD2fbSoWr6kl0EUugR+FT02Bpicc5IyAzevGQkkO6owRXvmoIQHBon1mcRGi5U8uNQdOi4zpM9rcDbtWXAWhxKADQOhlwFNL91cWhh0wI7Bmepx8frRmkcD1pBzI/ebdyZzK4ExG3j5zbtr+kNIKIePbTdHYVlWHnM9cNT2wOcu320r9TC5nV0y8Hcum95CKpVRlnfQGIVIB/B19jfnstpB6dwNdUGTDoTrimSNq+MDlY8fjLqkRmFmdP0xtlvLpG6mgjhOGmVofOrH89E+nC0Xrk7g7xu6n4vok8Nf0cImNzYS3INValRsfWTQmyBDyCmnP4Sjv2+T97QX7WC47s2WYBwNCmudvZF1ton0cIdUh6isuxbFy2Njr3FMau0/1w9YpunMJQ7f90bbmIo0J1ozXaiJO8HayG1bm99i5BBYmqlz+6JFjMDMVIjGIkG2+OzTW5s6e3PzXEU4oM6OEiYrVjSQ4FTYsSd8wbqQ+tCa2fF9W+TT1lZ0/82Do0yr/FeIB9hnNzsUcoutyh++hek9Ry00+8had9TJmnw77zzZY+nwnAVBT5criMQkuRr3UKAyaMQUdpMfn0GSIY9KBbnwrNzapMg6XRdMSeIbg5YbYcE0qmOUn4AZsPfmEn0WAvgPYB7olLjMVrghUcOtJ7pvWpj51NHxqJPW1EnS6ed4vc30/uss='}}], additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-3-flash-preview', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c86bc-3511-72f0-bcb3-108662d95044-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 1820, 'output_tokens': 485, 'total_tokens': 2305, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 385}})]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.tools import tool \n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Configure your API key\n",
    "load_dotenv(\"GoogleAPI.env\") \n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "print(GOOGLE_API_KEY)\n",
    "\n",
    "# Prompt\n",
    "Prompt = \"\"\"You are a Senior Fraud Investigator.\n",
    "You will be given a transaction and its SHAP explanations.\n",
    "Use your tools to check the user's history and bank policy.\n",
    "Then, write a 3-sentence memo concluding if it is fraud or not.\"\"\"\n",
    "\n",
    "# 1. Define Tools\n",
    "tools = [get_user_transactions, search_bank_policy]\n",
    "\n",
    "# 2. Initialize the model\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-3-flash-preview\",\n",
    "    api_key = GOOGLE_API_KEY,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Initialize the agent\n",
    "agent = create_agent(llm, tools, system_prompt= Prompt)\n",
    "\n",
    "\n",
    "# 4. Run the agent with dynamic query from SHAP\n",
    "reasons_str = \"\\n\".join([f\"- {r}\" for r in explanation['top_reasons']])\n",
    "query = f\"\"\"\n",
    "Investigate transaction for {investigated_user_id}.\n",
    "Model Fraud Probability: {explanation['score']:.2f}\n",
    "Top SHAP Contributing Factors:\n",
    "{reasons_str}\n",
    "\n",
    "Please check the user's transaction history and cross-reference with bank policy to generate a final memo.\n",
    "\"\"\"\n",
    "agent.invoke({\"messages\": [(\"user\", query)]})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.12 (venv)",
   "language": "python",
   "name": "python_3_12_12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

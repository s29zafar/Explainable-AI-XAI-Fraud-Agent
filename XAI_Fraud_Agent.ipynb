{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3de9146b",
   "metadata": {},
   "source": [
    "# XAI Fraud Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7846697",
   "metadata": {},
   "source": [
    "## Phase 1: The ML & Explainability Layer\n",
    "\n",
    "### Import Libraries for XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d19ec00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saimzafar2002-apple.com/venvs/python_3_12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0a3958",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76bb803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_transaction(transaction_row, preprocessor=None):\n",
    "    \"\"\"\n",
    "    Helper function to preprocess a single transaction row.\n",
    "    Returns processed DataFrame.\n",
    "    \"\"\"\n",
    "    # Convert to DataFrame if it's a dict or Series\n",
    "    if not isinstance(transaction_row, pd.DataFrame):\n",
    "        df_input = pd.DataFrame([transaction_row])\n",
    "    else:\n",
    "        df_input = transaction_row.copy()\n",
    "        \n",
    "    # 1. Drop irrelevant columns\n",
    "    cols_to_drop = ['month', 'device_fraud_count', 'fraud_bool']\n",
    "    df_input = df_input.drop(columns=[c for c in cols_to_drop if c in df_input.columns], errors='ignore')\n",
    "    \n",
    "    # 2. Convert types\n",
    "    for col in df_input.columns:\n",
    "        if col not in ['payment_type', 'employment_status', 'housing_status', 'source', 'device_os']:\n",
    "             df_input[col] = pd.to_numeric(df_input[col], errors='coerce')\n",
    "                \n",
    "    # 3. Handle Missing Values\n",
    "    missing_cols = [\n",
    "        \"prev_address_months_count\", \"current_address_months_count\",\n",
    "        \"bank_months_count\", \"session_length_in_minutes\"\n",
    "    ]\n",
    "    for col in missing_cols:\n",
    "        if col in df_input.columns:\n",
    "             df_input[col] = df_input[col].replace(-1, np.nan)\n",
    "    \n",
    "    # 4. Apply OneHotEncoding\n",
    "    if preprocessor:\n",
    "        try:\n",
    "            X_transformed = preprocessor.transform(df_input)\n",
    "            return X_transformed\n",
    "        except Exception as e:\n",
    "            print(f\"Preprocessing error: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        return df_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6f2518",
   "metadata": {},
   "source": [
    "### Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd13354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(transaction_row, preprocessor, model_params_path='XGBoostModelParameters.json', model_path='XGBoostModel.json'):\n",
    "    \"\"\"\n",
    "    Takes a single transaction row, preprocesses it, and returns the fraud probability.\n",
    "    \"\"\"\n",
    "    # Load parameters\n",
    "    try:\n",
    "        with open(model_params_path, 'r') as file:\n",
    "            loaded_params = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {model_params_path} not found.\")\n",
    "        return None\n",
    "\n",
    "    X_transformed = preprocess_transaction(transaction_row, preprocessor)\n",
    "    if X_transformed is None:\n",
    "        return None\n",
    "    \n",
    "    X_numpy = X_transformed.to_numpy()\n",
    "\n",
    "    # Load Model (Note: This assumes model file exists)\n",
    "    try:\n",
    "        model = xgb.XGBClassifier(**loaded_params)\n",
    "        model.load_model(model_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Inference\n",
    "    try:\n",
    "        probability = model.predict_proba(X_numpy)[0, 1]\n",
    "        return float(probability)\n",
    "    except Exception as e:\n",
    "        print(f\"Prediction error: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8f239f",
   "metadata": {},
   "source": [
    "### Create SHAP Explanation Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f290ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shap_explanation(transaction_data, model, preprocessor):\n",
    "    \"\"\"\n",
    "    Generates a SHAP explanation for a single transaction.\n",
    "    Returns a dictionary with fraud probability and top 3 contributing features.\n",
    "    \"\"\"\n",
    "    # Preprocess\n",
    "    X_transformed = preprocess_transaction(transaction_data, preprocessor)\n",
    "    if X_transformed is None:\n",
    "        return {\"error\": \"Preprocessing failed\"}\n",
    "    \n",
    "    # Ensure we use DataFrame for column names in SHAP\n",
    "    feature_names = preprocessor.get_feature_names_out() if hasattr(preprocessor, 'get_feature_names_out') else X_transformed.columns\n",
    "    X_df = pd.DataFrame(X_transformed, columns=feature_names)\n",
    "    \n",
    "    # Calculate SHAP values\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer(X_df)\n",
    "    \n",
    "    # Get values for the first (and only) row\n",
    "    # shap_values.values shape is (1, n_features)\n",
    "    # Binary classification: some shap versions output values for both classes, some just one.\n",
    "    # For XGBClassifier binary, it usually outputs log-odds for class 1.\n",
    "    \n",
    "    row_values = shap_values.values[0]\n",
    "    # base_value = shap_values.base_values[0] # Not strictly needed for top 3\n",
    "    data_values = X_df.iloc[0]\n",
    "    \n",
    "    # Calculate probability\n",
    "    prob = model.predict_proba(X_df)[0, 1]\n",
    "    \n",
    "    # Identify top 3 features pushing score HIGHER (positive contribution to fraud class)\n",
    "    # We want features that increase the probability of fraud.\n",
    "    \n",
    "    # Create list of (feature_name, shap_value, feature_value)\n",
    "    contributions = []\n",
    "    \n",
    "    # Handle multi-class output shape if SHAP returns (1, n_features, 2)\n",
    "    if len(row_values.shape) > 1:\n",
    "        # Assuming class 1 is index 1\n",
    "        row_values = row_values[:, 1]\n",
    "\n",
    "    for name, val, feat_val in zip(X_df.columns, row_values, data_values):\n",
    "        contributions.append((name, val, feat_val))\n",
    "    \n",
    "    # Sort by SHAP value descending (highest positive impact first)\n",
    "    contributions.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    top_3 = contributions[:3]\n",
    "    \n",
    "    top_reasons = []\n",
    "    for name, val, feat_val in top_3:\n",
    "        # Clean up feature name (remove 'cat__' etc if present)\n",
    "        clean_name = str(name).replace('cat__', '').replace('remainder__', '')\n",
    "        \n",
    "        # Format based on value type\n",
    "        if isinstance(feat_val, (int, float)):\n",
    "             reason = f\"{clean_name} = {feat_val:.2f}\"\n",
    "        else:\n",
    "             reason = f\"{clean_name} = {feat_val}\"\n",
    "        \n",
    "        top_reasons.append(reason)\n",
    "        \n",
    "    return {\n",
    "        \"score\": float(prob),\n",
    "        \"top_reasons\": top_reasons\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2443c15c",
   "metadata": {},
   "source": [
    "## Phase 2: The Data Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2ef7f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       fraud_bool  income  name_email_similarity  prev_address_months_count  \\\n",
      "0               0     0.7               0.523318                         -1   \n",
      "1               0     0.8               0.873555                         -1   \n",
      "2               0     0.8               0.999981                         -1   \n",
      "3               0     0.1               0.700272                        110   \n",
      "4               0     0.8               0.990024                         86   \n",
      "...           ...     ...                    ...                        ...   \n",
      "48417           0     0.9               0.068822                         93   \n",
      "48418           0     0.8               0.898829                         -1   \n",
      "48419           0     0.6               0.863616                         61   \n",
      "48420           0     0.9               0.843187                         -1   \n",
      "48421           0     0.1               0.893419                         -1   \n",
      "\n",
      "       current_address_months_count  customer_age  days_since_request  \\\n",
      "0                                16            30            0.019999   \n",
      "1                                42            20            0.006915   \n",
      "2                                 7            40            0.004779   \n",
      "3                                 9            40            0.006472   \n",
      "4                                 3            50            0.005070   \n",
      "...                             ...           ...                 ...   \n",
      "48417                            15            30            0.004301   \n",
      "48418                           177            40            0.003714   \n",
      "48419                             8            30            0.004969   \n",
      "48420                            29            50            0.009664   \n",
      "48421                           114            30            0.019562   \n",
      "\n",
      "       intended_balcon_amount payment_type  zip_count_4w  ...  \\\n",
      "0                   -0.968113           AB           857  ...   \n",
      "1                   -0.434567           AD           732  ...   \n",
      "2                   -1.613760           AC           924  ...   \n",
      "3                   37.839432           AA          2073  ...   \n",
      "4                   52.905777           AA          1589  ...   \n",
      "...                       ...          ...           ...  ...   \n",
      "48417               -0.539760           AB          1542  ...   \n",
      "48418               -0.378959           AC           707  ...   \n",
      "48419               19.149816           AB           914  ...   \n",
      "48420               -0.928304           AB          2376  ...   \n",
      "48421               -1.536147           AC          1424  ...   \n",
      "\n",
      "       has_other_cards  proposed_credit_limit  foreign_request    source  \\\n",
      "0                    0                  200.0                0  INTERNET   \n",
      "1                    0                  200.0                0  INTERNET   \n",
      "2                    0                  200.0                0  INTERNET   \n",
      "3                    0                  200.0                0  INTERNET   \n",
      "4                    1                  500.0                0  INTERNET   \n",
      "...                ...                    ...              ...       ...   \n",
      "48417                1                 1000.0                0  INTERNET   \n",
      "48418                1                 1000.0                0  INTERNET   \n",
      "48419                1                  200.0                0  INTERNET   \n",
      "48420                0                  200.0                0  INTERNET   \n",
      "48421                0                  200.0                0  INTERNET   \n",
      "\n",
      "       session_length_in_minutes device_os  keep_alive_session  \\\n",
      "0                       3.357721   windows                   1   \n",
      "1                       3.416515     other                   1   \n",
      "2                       4.886302     other                   1   \n",
      "3                      28.860248   windows                   1   \n",
      "4                       6.375665   windows                   0   \n",
      "...                          ...       ...                 ...   \n",
      "48417                   6.275100   windows                   0   \n",
      "48418                   1.900696     other                   0   \n",
      "48419                   2.572849     other                   0   \n",
      "48420                   1.599111     other                   1   \n",
      "48421                   4.062816   windows                   0   \n",
      "\n",
      "       device_distinct_emails_8w device_fraud_count    user_id  \n",
      "0                              1                  0  USER_0000  \n",
      "1                              1                  0  USER_0001  \n",
      "2                              1                  0  USER_0002  \n",
      "3                              1                  0  USER_0003  \n",
      "4                              1                  0  USER_0004  \n",
      "...                          ...                ...        ...  \n",
      "48417                          1                  0  USER_0001  \n",
      "48418                          1                  0  USER_0002  \n",
      "48419                          1                  0  USER_0003  \n",
      "48420                          1                  0  USER_0004  \n",
      "48421                          1                  0  USER_0005  \n",
      "\n",
      "[48422 rows x 32 columns]\n",
      "\n",
      "Data read from SQLite table:\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import kagglehub\n",
    "from faker import Faker\n",
    "\n",
    "# Setup SQLLite connection \n",
    "connection = sqlite3.connect(\"Fraud_Agent.db\")\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"sgpjesus/bank-account-fraud-dataset-neurips-2022\")\n",
    "\n",
    "#print(\"Path to dataset files:\", path)\n",
    "# ensure we point to a .csv file (dataset_download may return a path without extension)\n",
    "csv_path = str(path) + \"/Base.csv\"\n",
    "\n",
    "# read the CSV into a DataFrame and setup the final test data\n",
    "df_OG = pd.read_csv(csv_path)\n",
    "mask = df_OG[\"month\"] == 7\n",
    "\n",
    "full_test_data = df_OG[mask].sample(frac=0.5).reset_index(drop=True).drop('month',axis=1) \n",
    "\n",
    "df = full_test_data\n",
    "\n",
    "# Add \n",
    "fake = Faker()\n",
    "num_users = len(df) // 8\n",
    "user_ids = [f\"USER_{i:04d}\" for i in range(num_users)]\n",
    "\n",
    "df['user_id'] = (user_ids * 9)[:len(df)]\n",
    "\n",
    "print(df)\n",
    "\n",
    "# Setup a Table in SQL\n",
    "table_name = \"transaction_history\"\n",
    "full_test_data.to_sql(table_name, connection, if_exists='replace', index=False)\n",
    "\n",
    "# Verify the data was written by reading it back into a new DataFrame\n",
    "query = f\"SELECT * FROM {table_name}\"\n",
    "result_df = pd.read_sql_query(query, connection)\n",
    "print(\"\\nData read from SQLite table:\")\n",
    "#print(result_df)\n",
    "\n",
    "# Close the database connection\n",
    "connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74799e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the database is: 13254656 bytes (via PRAGMA)\n"
     ]
    }
   ],
   "source": [
    "def get_db_size_pragma(db_path):\n",
    "    \"\"\"\n",
    "    Gets the size of a SQLite database in bytes using PRAGMA statements.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Get page count\n",
    "    cursor.execute(\"PRAGMA page_count;\")\n",
    "    page_count = cursor.fetchone()[0]\n",
    "\n",
    "    # Get page size\n",
    "    cursor.execute(\"PRAGMA page_size;\")\n",
    "    page_size = cursor.fetchone()[0]\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    # Calculate total size in bytes\n",
    "    size_in_bytes = page_count * page_size\n",
    "    return size_in_bytes\n",
    "\n",
    "db_file_path = \"Fraud_Agent.db\"\n",
    "size = get_db_size_pragma(db_file_path)\n",
    "\n",
    "print(f\"The size of the database is: {size} bytes (via PRAGMA)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89175624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.remove(\"Fraud_Agent.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c920822",
   "metadata": {},
   "source": [
    "### The Vector Store. \n",
    "Write a script to read that PDF, split it into chunks using LangChain's RecursiveCharacterTextSplitter, and save it into a local ChromaDB vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fa5a430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Fraud_Detection_Policy.pdf...\n",
      "Splitting text...\n",
      "Created 3 chunks.\n",
      "Initializing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 1395.74it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ChromaDB client...\n",
      "Adding documents to collection 'bank_policies'...\n",
      "Successfully added 3 chunks to ChromaDB at ./chroma_db\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import chromadb\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Fix for SQLite on Mac (common issue with ChromaDB)\n",
    "import sqlite3\n",
    "import sys\n",
    "if sys.platform.startswith('darwin'):\n",
    "    try:\n",
    "        __import__('pysqlite3')\n",
    "        sys.modules['sqlite3'] = sys.modules['pysqlite3']\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "# Configuration\n",
    "CHROMA_PATH = \"./chroma_db\"\n",
    "CHROMA_COLLECTION_NAME = \"bank_policies\"\n",
    "PDF_PATH = \"Fraud_Detection_Policy.pdf\"\n",
    "\n",
    "def ingest_pdf():\n",
    "    # 1. Load PDF\n",
    "    if not os.path.exists(PDF_PATH):\n",
    "        print(f\"Error: {PDF_PATH} not found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loading {PDF_PATH}...\")\n",
    "    loader = PyPDFLoader(PDF_PATH)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # 2. Split Text\n",
    "    print(\"Splitting text...\")\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    chunked_documents = text_splitter.split_documents(documents)\n",
    "    \n",
    "    print(f\"Created {len(chunked_documents)} chunks.\")\n",
    "\n",
    "    # 3. Initialize Embeddings\n",
    "    print(\"Initializing embeddings...\")\n",
    "    embedding_function = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    # 4. Initialize Chroma Client\n",
    "    print(\"Initializing ChromaDB client...\")\n",
    "    chroma_client = chromadb.PersistentClient(path=CHROMA_PATH)\n",
    "\n",
    "    # 5. Add to Chroma\n",
    "    print(f\"Adding documents to collection '{CHROMA_COLLECTION_NAME}'...\")\n",
    "    Chroma.from_documents(\n",
    "        documents=chunked_documents,\n",
    "        embedding=embedding_function,\n",
    "        collection_name=CHROMA_COLLECTION_NAME,\n",
    "        client=chroma_client,\n",
    "    )\n",
    "    \n",
    "    print(f\"Successfully added {len(chunked_documents)} chunks to ChromaDB at {CHROMA_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ingest_pdf()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02529dc",
   "metadata": {},
   "source": [
    "## Building the Agent's \"Tools\" \n",
    "Step 3.1: Database Tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b951fd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data read from SQLite table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraud_bool</th>\n",
       "      <th>income</th>\n",
       "      <th>name_email_similarity</th>\n",
       "      <th>prev_address_months_count</th>\n",
       "      <th>current_address_months_count</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>days_since_request</th>\n",
       "      <th>intended_balcon_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>zip_count_4w</th>\n",
       "      <th>...</th>\n",
       "      <th>has_other_cards</th>\n",
       "      <th>proposed_credit_limit</th>\n",
       "      <th>foreign_request</th>\n",
       "      <th>source</th>\n",
       "      <th>session_length_in_minutes</th>\n",
       "      <th>device_os</th>\n",
       "      <th>keep_alive_session</th>\n",
       "      <th>device_distinct_emails_8w</th>\n",
       "      <th>device_fraud_count</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.523318</td>\n",
       "      <td>-1</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>0.019999</td>\n",
       "      <td>-0.968113</td>\n",
       "      <td>AB</td>\n",
       "      <td>857</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>3.357721</td>\n",
       "      <td>windows</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>USER_0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.307123</td>\n",
       "      <td>60</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>0.022186</td>\n",
       "      <td>-1.372846</td>\n",
       "      <td>AB</td>\n",
       "      <td>1149</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>2.908656</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>USER_0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.507479</td>\n",
       "      <td>-1</td>\n",
       "      <td>214</td>\n",
       "      <td>50</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>-0.857296</td>\n",
       "      <td>AB</td>\n",
       "      <td>750</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>2.856984</td>\n",
       "      <td>windows</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>USER_0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.884954</td>\n",
       "      <td>-1</td>\n",
       "      <td>145</td>\n",
       "      <td>40</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>-1.502515</td>\n",
       "      <td>AC</td>\n",
       "      <td>1330</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>1.713412</td>\n",
       "      <td>linux</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>USER_0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.072035</td>\n",
       "      <td>-1</td>\n",
       "      <td>170</td>\n",
       "      <td>40</td>\n",
       "      <td>0.022907</td>\n",
       "      <td>14.367664</td>\n",
       "      <td>AA</td>\n",
       "      <td>1286</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>4.331581</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>USER_0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fraud_bool  income  name_email_similarity  prev_address_months_count  \\\n",
       "0           0     0.7               0.523318                         -1   \n",
       "1           0     0.6               0.307123                         60   \n",
       "2           0     0.9               0.507479                         -1   \n",
       "3           0     0.6               0.884954                         -1   \n",
       "4           0     0.7               0.072035                         -1   \n",
       "\n",
       "   current_address_months_count  customer_age  days_since_request  \\\n",
       "0                            16            30            0.019999   \n",
       "1                            14            30            0.022186   \n",
       "2                           214            50            0.005081   \n",
       "3                           145            40            0.000755   \n",
       "4                           170            40            0.022907   \n",
       "\n",
       "   intended_balcon_amount payment_type  zip_count_4w  ...  has_other_cards  \\\n",
       "0               -0.968113           AB           857  ...                0   \n",
       "1               -1.372846           AB          1149  ...                0   \n",
       "2               -0.857296           AB           750  ...                0   \n",
       "3               -1.502515           AC          1330  ...                1   \n",
       "4               14.367664           AA          1286  ...                1   \n",
       "\n",
       "   proposed_credit_limit  foreign_request    source  \\\n",
       "0                  200.0                0  INTERNET   \n",
       "1                 1500.0                0  INTERNET   \n",
       "2                 1500.0                0  INTERNET   \n",
       "3                  200.0                0  INTERNET   \n",
       "4                  200.0                0  INTERNET   \n",
       "\n",
       "   session_length_in_minutes device_os  keep_alive_session  \\\n",
       "0                   3.357721   windows                   1   \n",
       "1                   2.908656     other                   1   \n",
       "2                   2.856984   windows                   1   \n",
       "3                   1.713412     linux                   1   \n",
       "4                   4.331581     other                   1   \n",
       "\n",
       "   device_distinct_emails_8w device_fraud_count    user_id  \n",
       "0                          1                  0  USER_0000  \n",
       "1                          1                  0  USER_0000  \n",
       "2                          1                  0  USER_0000  \n",
       "3                          1                  0  USER_0000  \n",
       "4                          1                  0  USER_0000  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_user_transactions(user_id: str):\n",
    "    db_path = \"Fraud_Agent.db\"\n",
    "\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # SELECT any 5 transactions of the user at random\n",
    "    query = f\"SELECT * FROM transaction_history WHERE user_id = '{user_id}' LIMIT 5\"\n",
    "    result_df = pd.read_sql_query(query, conn)\n",
    "    print(\"\\nData read from SQLite table:\")\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    return result_df\n",
    "\n",
    "user_id = 'USER_0000'\n",
    "\n",
    "get_user_transactions(user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f53859",
   "metadata": {},
   "source": [
    "## Policy RAG Tool\n",
    "Write a function search_bank_policy(query: str) that queries your ChromaDB and returns the most relevant paragraph from your PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfdfbdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j_/r592xntd31b897xl6vt_hhl00000gn/T/ipykernel_11143/2268385787.py:22: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 704.86it/s, Materializing param=pooler.dense.weight]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Found: Housing Status (BE, BB, BC): These anonymized categories are historically associated with lower\n",
      "fraud rates.\n",
      "Escalation Rules\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j_/r592xntd31b897xl6vt_hhl00000gn/T/ipykernel_11143/2268385787.py:27: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the `langchain-chroma package and should be used instead. To use it run `pip install -U `langchain-chroma` and import as `from `langchain_chroma import Chroma``.\n",
      "  vector_db = Chroma(\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from transformers import logging as transformers_logging\n",
    "transformers_logging.set_verbosity_error()\n",
    "logging.getLogger(\"huggingface_hub\").setLevel(logging.ERROR)\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.tools import tool\n",
    "import chromadb\n",
    "import sys\n",
    "\n",
    "# Fix for SQLite on Mac (common issue with ChromaDB)\n",
    "if sys.platform.startswith('darwin'):\n",
    "    try:\n",
    "        __import__('pysqlite3')\n",
    "        sys.modules['sqlite3'] = sys.modules['pysqlite3']\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "CHROMA_PATH = \"./chroma_db\"\n",
    "CHROMA_COLLECTION_NAME = \"bank_policies\"\n",
    "\n",
    "@tool\n",
    "def search_bank_policy(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Searches the official Bank Anti-Fraud Policy documentation. \n",
    "    Use this tool when you need to verify if a flagged transaction \n",
    "    violates specific banking regulations or internal risk thresholds.\n",
    "    \"\"\"\n",
    "    # Consistency: Use same embeddings and paths as ingestion\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    # Initialize Persistent Client\n",
    "    chroma_client = chromadb.PersistentClient(path=CHROMA_PATH)\n",
    "\n",
    "    vector_db = Chroma(\n",
    "        client=chroma_client,\n",
    "        embedding_function=embeddings,\n",
    "        collection_name=CHROMA_COLLECTION_NAME\n",
    "    )\n",
    "    \n",
    "    # Perform the Similarity Search\n",
    "    # k=1 returns only the single most relevant paragraph\n",
    "    docs = vector_db.similarity_search(query, k=1)\n",
    "    \n",
    "    if not docs:\n",
    "        return \"No relevant policy found for this query.\"\n",
    "    \n",
    "    # Return the text content of the best match\n",
    "    return docs[0].page_content\n",
    "\n",
    "# Test the tool manually\n",
    "try:\n",
    "    # result = search_bank_policy.invoke(\"What is the limit for overseas wire transfers?\")\n",
    "    result = search_bank_policy.invoke(\"housing status\")\n",
    "    print(f\"Policy Found: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during search: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71ddd8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..EE\n",
      "======================================================================\n",
      "ERROR: test_search_bank_policy_content (__main__.TestCoreTools.test_search_bank_policy_content)\n",
      "Verify that search_bank_policy returns relevant content.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/j_/r592xntd31b897xl6vt_hhl00000gn/T/ipykernel_11143/3919581003.py\", line 54, in test_search_bank_policy_content\n",
      "    result = search_bank_policy(\"risk indicators\")\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: 'StructuredTool' object is not callable\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_search_bank_policy_output_type (__main__.TestCoreTools.test_search_bank_policy_output_type)\n",
      "Verify that search_bank_policy returns a string.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/j_/r592xntd31b897xl6vt_hhl00000gn/T/ipykernel_11143/3919581003.py\", line 44, in test_search_bank_policy_output_type\n",
      "    result = search_bank_policy(\"housing status\")\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: 'StructuredTool' object is not callable\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.055s\n",
      "\n",
      "FAILED (errors=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data read from SQLite table:\n",
      "\n",
      "[PASSED] get_user_transactions returns a DataFrame.\n",
      "\n",
      "Data read from SQLite table:\n",
      "[PASSED] get_user_transactions returned 5 rows for USER_0000.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1301bc410>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "from transformers import logging as transformers_logging\n",
    "transformers_logging.set_verbosity_error()\n",
    "logging.getLogger(\"huggingface_hub\").setLevel(logging.ERROR)\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "import unittest\n",
    "\n",
    "# Fix for SQLite on Mac (common issue with ChromaDB)\n",
    "if sys.platform.startswith('darwin'):\n",
    "    try:\n",
    "        __import__('pysqlite3')\n",
    "        sys.modules['sqlite3'] = sys.modules['pysqlite3']\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "# --- Unit Tests ---\n",
    "class TestCoreTools(unittest.TestCase):\n",
    "    \n",
    "    def test_get_user_transactions_output_type(self):\n",
    "        \"\"\"Verify that get_user_transactions returns a pandas DataFrame.\"\"\"\n",
    "        # Using a sample user ID from the database\n",
    "        df = get_user_transactions(\"USER_0000\")\n",
    "        if df is not None:\n",
    "            self.assertIsInstance(df, pd.DataFrame)\n",
    "            print(\"\\n[PASSED] get_user_transactions returns a DataFrame.\")\n",
    "        else:\n",
    "            self.skipTest(\"Fraud_Agent.db not found for integration test.\")\n",
    "\n",
    "    def test_get_user_transactions_valid_user(self):\n",
    "        \"\"\"Verify that get_user_transactions returns data for a valid user.\"\"\"\n",
    "        df = get_user_transactions(\"USER_0000\")\n",
    "        if df is not None:\n",
    "            # We know USER_0000 exists if the database was setup correctly\n",
    "            # If the DB is empty, this might be 0, but it should still be a DF\n",
    "            self.assertTrue(len(df) >= 0)\n",
    "            print(f\"[PASSED] get_user_transactions returned {len(df)} rows for USER_0000.\")\n",
    "        else:\n",
    "            self.skipTest(\"Fraud_Agent.db not found for integration test.\")\n",
    "\n",
    "    def test_search_bank_policy_output_type(self):\n",
    "        \"\"\"Verify that search_bank_policy returns a string.\"\"\"\n",
    "        if os.path.exists(\"./chroma_db\"):\n",
    "            result = search_bank_policy(\"housing status\")\n",
    "            self.assertIsInstance(result, str)\n",
    "            self.assertNotEqual(result, \"No relevant policy found for this query.\")\n",
    "            print(\"[PASSED] search_bank_policy returns a valid string.\")\n",
    "        else:\n",
    "            self.skipTest(\"./chroma_db not found for integration test.\")\n",
    "\n",
    "    def test_search_bank_policy_content(self):\n",
    "        \"\"\"Verify that search_bank_policy returns relevant content.\"\"\"\n",
    "        if os.path.exists(\"./chroma_db\"):\n",
    "            result = search_bank_policy(\"risk indicators\")\n",
    "            self.assertTrue(len(result) > 10)\n",
    "            print(f\"[PASSED] search_bank_policy returned relevant content: {result[:50]}...\")\n",
    "        else:\n",
    "            self.skipTest(\"./chroma_db not found for integration test.\")\n",
    "\n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.12 (venv)",
   "language": "python",
   "name": "python_3_12_12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3de9146b",
   "metadata": {},
   "source": [
    "# XAI Fraud Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7846697",
   "metadata": {},
   "source": [
    "## Phase 1: The ML & Explainability Layer\n",
    "\n",
    "### Import Libraries for XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d19ec00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saimzafar2002-apple.com/venvs/python_3_12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0a3958",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76bb803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_transaction(transaction_row, preprocessor=None):\n",
    "    \"\"\"\n",
    "    Helper function to preprocess a single transaction row.\n",
    "    Returns processed DataFrame.\n",
    "    \"\"\"\n",
    "    # Convert to DataFrame if it's a dict or Series\n",
    "    if not isinstance(transaction_row, pd.DataFrame):\n",
    "        df_input = pd.DataFrame([transaction_row])\n",
    "    else:\n",
    "        df_input = transaction_row.copy()\n",
    "        \n",
    "    # 1. Drop irrelevant columns\n",
    "    cols_to_drop = ['month', 'device_fraud_count', 'fraud_bool']\n",
    "    df_input = df_input.drop(columns=[c for c in cols_to_drop if c in df_input.columns], errors='ignore')\n",
    "    \n",
    "    # 2. Convert types\n",
    "    for col in df_input.columns:\n",
    "        if col not in ['payment_type', 'employment_status', 'housing_status', 'source', 'device_os']:\n",
    "             df_input[col] = pd.to_numeric(df_input[col], errors='coerce')\n",
    "                \n",
    "    # 3. Handle Missing Values\n",
    "    missing_cols = [\n",
    "        \"prev_address_months_count\", \"current_address_months_count\",\n",
    "        \"bank_months_count\", \"session_length_in_minutes\"\n",
    "    ]\n",
    "    for col in missing_cols:\n",
    "        if col in df_input.columns:\n",
    "             df_input[col] = df_input[col].replace(-1, np.nan)\n",
    "    \n",
    "    # 4. Apply OneHotEncoding\n",
    "    if preprocessor:\n",
    "        try:\n",
    "            X_transformed = preprocessor.transform(df_input)\n",
    "            return X_transformed\n",
    "        except Exception as e:\n",
    "            print(f\"Preprocessing error: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        return df_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6f2518",
   "metadata": {},
   "source": [
    "### Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd13354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(transaction_row, preprocessor, model_params_path='XGBoostModelParameters.json', model_path='XGBoostModel.json'):\n",
    "    \"\"\"\n",
    "    Takes a single transaction row, preprocesses it, and returns the fraud probability.\n",
    "    \"\"\"\n",
    "    # Load parameters\n",
    "    try:\n",
    "        with open(model_params_path, 'r') as file:\n",
    "            loaded_params = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {model_params_path} not found.\")\n",
    "        return None\n",
    "\n",
    "    X_transformed = preprocess_transaction(transaction_row, preprocessor)\n",
    "    if X_transformed is None:\n",
    "        return None\n",
    "    \n",
    "    X_numpy = X_transformed.to_numpy()\n",
    "\n",
    "    # Load Model (Note: This assumes model file exists)\n",
    "    try:\n",
    "        model = xgb.XGBClassifier(**loaded_params)\n",
    "        model.load_model(model_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Inference\n",
    "    try:\n",
    "        probability = model.predict_proba(X_numpy)[0, 1]\n",
    "        return float(probability)\n",
    "    except Exception as e:\n",
    "        print(f\"Prediction error: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8f239f",
   "metadata": {},
   "source": [
    "### Create SHAP Explanation Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f290ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shap_explanation(transaction_data, model, preprocessor):\n",
    "    \"\"\"\n",
    "    Generates a SHAP explanation for a single transaction.\n",
    "    Returns a dictionary with fraud probability and top 3 contributing features.\n",
    "    \"\"\"\n",
    "    # Preprocess\n",
    "    X_transformed = preprocess_transaction(transaction_data, preprocessor)\n",
    "    if X_transformed is None:\n",
    "        return {\"error\": \"Preprocessing failed\"}\n",
    "    \n",
    "    # Ensure we use DataFrame for column names in SHAP\n",
    "    feature_names = preprocessor.get_feature_names_out() if hasattr(preprocessor, 'get_feature_names_out') else X_transformed.columns\n",
    "    X_df = pd.DataFrame(X_transformed, columns=feature_names)\n",
    "    \n",
    "    # Calculate SHAP values\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer(X_df)\n",
    "    \n",
    "    # Get values for the first (and only) row\n",
    "    # shap_values.values shape is (1, n_features)\n",
    "    # Binary classification: some shap versions output values for both classes, some just one.\n",
    "    # For XGBClassifier binary, it usually outputs log-odds for class 1.\n",
    "    \n",
    "    row_values = shap_values.values[0]\n",
    "    # base_value = shap_values.base_values[0] # Not strictly needed for top 3\n",
    "    data_values = X_df.iloc[0]\n",
    "    \n",
    "    # Calculate probability\n",
    "    prob = model.predict_proba(X_df)[0, 1]\n",
    "    \n",
    "    # Identify top 3 features pushing score HIGHER (positive contribution to fraud class)\n",
    "    # We want features that increase the probability of fraud.\n",
    "    \n",
    "    # Create list of (feature_name, shap_value, feature_value)\n",
    "    contributions = []\n",
    "    \n",
    "    # Handle multi-class output shape if SHAP returns (1, n_features, 2)\n",
    "    if len(row_values.shape) > 1:\n",
    "        # Assuming class 1 is index 1\n",
    "        row_values = row_values[:, 1]\n",
    "\n",
    "    for name, val, feat_val in zip(X_df.columns, row_values, data_values):\n",
    "        contributions.append((name, val, feat_val))\n",
    "    \n",
    "    # Sort by SHAP value descending (highest positive impact first)\n",
    "    contributions.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    top_3 = contributions[:3]\n",
    "    \n",
    "    top_reasons = []\n",
    "    for name, val, feat_val in top_3:\n",
    "        # Clean up feature name (remove 'cat__' etc if present)\n",
    "        clean_name = str(name).replace('cat__', '').replace('remainder__', '')\n",
    "        \n",
    "        # Format based on value type\n",
    "        if isinstance(feat_val, (int, float)):\n",
    "             reason = f\"{clean_name} = {feat_val:.2f}\"\n",
    "        else:\n",
    "             reason = f\"{clean_name} = {feat_val}\"\n",
    "        \n",
    "        top_reasons.append(reason)\n",
    "        \n",
    "    return {\n",
    "        \"score\": float(prob),\n",
    "        \"top_reasons\": top_reasons\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2443c15c",
   "metadata": {},
   "source": [
    "## Phase 2: The Data Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2ef7f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       fraud_bool  income  name_email_similarity  prev_address_months_count  \\\n",
      "0               0     0.9               0.161549                         -1   \n",
      "1               0     0.7               0.526118                         -1   \n",
      "2               0     0.3               0.322039                         -1   \n",
      "3               0     0.6               0.162843                         -1   \n",
      "4               0     0.1               0.345104                         -1   \n",
      "...           ...     ...                    ...                        ...   \n",
      "48417           0     0.3               0.132295                         29   \n",
      "48418           0     0.3               0.490528                         37   \n",
      "48419           0     0.9               0.838373                         33   \n",
      "48420           0     0.1               0.002002                         61   \n",
      "48421           0     0.9               0.706564                         -1   \n",
      "\n",
      "       current_address_months_count  customer_age  days_since_request  \\\n",
      "0                                34            30            0.009383   \n",
      "1                                27            30            0.016785   \n",
      "2                                27            30            0.014761   \n",
      "3                                63            40            0.016462   \n",
      "4                                27            20            0.017261   \n",
      "...                             ...           ...                 ...   \n",
      "48417                             4            30            0.034475   \n",
      "48418                            17            30            0.029142   \n",
      "48419                           182            40            0.017397   \n",
      "48420                             0            20            0.024768   \n",
      "48421                           141            30            0.004997   \n",
      "\n",
      "       intended_balcon_amount payment_type  zip_count_4w  ...  \\\n",
      "0                   -0.435790           AC           878  ...   \n",
      "1                   -1.127286           AB          1758  ...   \n",
      "2                   -0.465989           AB          1061  ...   \n",
      "3                   -1.225605           AC          1361  ...   \n",
      "4                    6.894004           AA          1505  ...   \n",
      "...                       ...          ...           ...  ...   \n",
      "48417               -0.701783           AB           444  ...   \n",
      "48418               51.837070           AA           434  ...   \n",
      "48419               -0.599463           AD          1333  ...   \n",
      "48420               -1.520780           AB           517  ...   \n",
      "48421               12.655645           AA          3070  ...   \n",
      "\n",
      "       has_other_cards  proposed_credit_limit  foreign_request    source  \\\n",
      "0                    0                  500.0                0  INTERNET   \n",
      "1                    0                 1500.0                1  INTERNET   \n",
      "2                    0                  200.0                0  INTERNET   \n",
      "3                    1                  200.0                0  INTERNET   \n",
      "4                    0                  200.0                0  INTERNET   \n",
      "...                ...                    ...              ...       ...   \n",
      "48417                0                 1500.0                0  INTERNET   \n",
      "48418                0                  200.0                0  INTERNET   \n",
      "48419                0                  200.0                0  INTERNET   \n",
      "48420                0                  200.0                0  INTERNET   \n",
      "48421                1                  500.0                0  INTERNET   \n",
      "\n",
      "       session_length_in_minutes device_os  keep_alive_session  \\\n",
      "0                       1.623622     linux                   1   \n",
      "1                       2.559368   windows                   0   \n",
      "2                       1.577453     linux                   1   \n",
      "3                       1.256647     other                   1   \n",
      "4                       6.290956     other                   1   \n",
      "...                          ...       ...                 ...   \n",
      "48417                   1.074625   windows                   0   \n",
      "48418                   2.509736     linux                   1   \n",
      "48419                   3.348152     linux                   1   \n",
      "48420                   9.871961   windows                   1   \n",
      "48421                   5.148915   windows                   1   \n",
      "\n",
      "       device_distinct_emails_8w device_fraud_count    user_id  \n",
      "0                              1                  0  USER_0000  \n",
      "1                              1                  0  USER_0001  \n",
      "2                              1                  0  USER_0002  \n",
      "3                              1                  0  USER_0003  \n",
      "4                              1                  0  USER_0004  \n",
      "...                          ...                ...        ...  \n",
      "48417                          1                  0  USER_0001  \n",
      "48418                          1                  0  USER_0002  \n",
      "48419                          1                  0  USER_0003  \n",
      "48420                          1                  0  USER_0004  \n",
      "48421                          1                  0  USER_0005  \n",
      "\n",
      "[48422 rows x 32 columns]\n",
      "\n",
      "Data read from SQLite table:\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import kagglehub\n",
    "from faker import Faker\n",
    "\n",
    "# Setup SQLLite connection \n",
    "connection = sqlite3.connect(\"Fraud_Agent.db\")\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"sgpjesus/bank-account-fraud-dataset-neurips-2022\")\n",
    "\n",
    "#print(\"Path to dataset files:\", path)\n",
    "# ensure we point to a .csv file (dataset_download may return a path without extension)\n",
    "csv_path = str(path) + \"/Base.csv\"\n",
    "\n",
    "# read the CSV into a DataFrame and setup the final test data\n",
    "df_OG = pd.read_csv(csv_path)\n",
    "mask = df_OG[\"month\"] == 7\n",
    "\n",
    "full_test_data = df_OG[mask].sample(frac=0.5).reset_index(drop=True).drop('month',axis=1) \n",
    "\n",
    "df = full_test_data\n",
    "\n",
    "# Add \n",
    "fake = Faker()\n",
    "num_users = len(df) // 8\n",
    "user_ids = [f\"USER_{i:04d}\" for i in range(num_users)]\n",
    "\n",
    "df['user_id'] = (user_ids * 9)[:len(df)]\n",
    "\n",
    "print(df)\n",
    "\n",
    "# Setup a Table in SQL\n",
    "table_name = \"transaction_history\"\n",
    "full_test_data.to_sql(table_name, connection, if_exists='replace', index=False)\n",
    "\n",
    "# Verify the data was written by reading it back into a new DataFrame\n",
    "query = f\"SELECT * FROM {table_name}\"\n",
    "result_df = pd.read_sql_query(query, connection)\n",
    "print(\"\\nData read from SQLite table:\")\n",
    "#print(result_df)\n",
    "\n",
    "# Close the database connection\n",
    "connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74799e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the database is: 7110656 bytes (via PRAGMA)\n"
     ]
    }
   ],
   "source": [
    "def get_db_size_pragma(db_path):\n",
    "    \"\"\"\n",
    "    Gets the size of a SQLite database in bytes using PRAGMA statements.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Get page count\n",
    "    cursor.execute(\"PRAGMA page_count;\")\n",
    "    page_count = cursor.fetchone()[0]\n",
    "\n",
    "    # Get page size\n",
    "    cursor.execute(\"PRAGMA page_size;\")\n",
    "    page_size = cursor.fetchone()[0]\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    # Calculate total size in bytes\n",
    "    size_in_bytes = page_count * page_size\n",
    "    return size_in_bytes\n",
    "\n",
    "db_file_path = \"Fraud_Agent.db\"\n",
    "size = get_db_size_pragma(db_file_path)\n",
    "\n",
    "print(f\"The size of the database is: {size} bytes (via PRAGMA)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89175624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.remove(\"Fraud_Agent.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c920822",
   "metadata": {},
   "source": [
    "### The Vector Store. \n",
    "Write a script to read that PDF, split it into chunks using LangChain's RecursiveCharacterTextSplitter, and save it into a local ChromaDB vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fa5a430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Fraud_Detection_Policy.pdf not found.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import chromadb\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Fix for SQLite on Mac (common issue with ChromaDB)\n",
    "import sqlite3\n",
    "import sys\n",
    "if sys.platform.startswith('darwin'):\n",
    "    try:\n",
    "        __import__('pysqlite3')\n",
    "        sys.modules['sqlite3'] = sys.modules['pysqlite3']\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "# Configuration\n",
    "CHROMA_PATH = \"./chroma_db\"\n",
    "CHROMA_COLLECTION_NAME = \"bank_policies\"\n",
    "PDF_PATH = \"Fraud_Detection_Policy.pdf\"\n",
    "\n",
    "def ingest_pdf():\n",
    "    # 1. Load PDF\n",
    "    if not os.path.exists(PDF_PATH):\n",
    "        print(f\"Error: {PDF_PATH} not found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loading {PDF_PATH}...\")\n",
    "    loader = PyPDFLoader(PDF_PATH)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # 2. Split Text\n",
    "    print(\"Splitting text...\")\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    chunked_documents = text_splitter.split_documents(documents)\n",
    "    \n",
    "    print(f\"Created {len(chunked_documents)} chunks.\")\n",
    "\n",
    "    # 3. Initialize Embeddings\n",
    "    print(\"Initializing embeddings...\")\n",
    "    embedding_function = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    # 4. Initialize Chroma Client\n",
    "    print(\"Initializing ChromaDB client...\")\n",
    "    chroma_client = chromadb.PersistentClient(path=CHROMA_PATH)\n",
    "\n",
    "    # 5. Add to Chroma\n",
    "    print(f\"Adding documents to collection '{CHROMA_COLLECTION_NAME}'...\")\n",
    "    Chroma.from_documents(\n",
    "        documents=chunked_documents,\n",
    "        embedding=embedding_function,\n",
    "        collection_name=CHROMA_COLLECTION_NAME,\n",
    "        client=chroma_client,\n",
    "    )\n",
    "    \n",
    "    print(f\"Successfully added {len(chunked_documents)} chunks to ChromaDB at {CHROMA_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ingest_pdf()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02529dc",
   "metadata": {},
   "source": [
    "## Building the Agent's \"Tools\" \n",
    "Step 3.1: Database Tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b951fd0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tool' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;129m@tool\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_user_transactions\u001b[39m(user_id: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m      3\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m    Randomly select 5 transactions for this user.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m    Use this tool when you need to verify if a user has a history of fraud\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m    transactions.\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m      8\u001b[39m     db_path = \u001b[33m\"\u001b[39m\u001b[33mFraud_Agent.db\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'tool' is not defined"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def get_user_transactions(user_id: str):\n",
    "    \"\"\"\n",
    "    Randomly select 5 transactions for this user.\n",
    "    Use this tool when you need to verify if a user has a history of fraud\n",
    "    transactions.\n",
    "    \"\"\"\n",
    "    db_path = \"Fraud_Agent.db\"\n",
    "\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # SELECT any 5 transactions of the user at random\n",
    "    query = f\"SELECT * FROM transaction_history WHERE user_id = '{user_id}' LIMIT 5\"\n",
    "    result_df = pd.read_sql_query(query, conn)\n",
    "    print(\"\\nData read from SQLite table:\")\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f53859",
   "metadata": {},
   "source": [
    "## Policy RAG Tool\n",
    "Write a function search_bank_policy(query: str) that queries your ChromaDB and returns the most relevant paragraph from your PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdfbdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 1148.92it/s, Materializing param=pooler.dense.weight]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Found: Housing Status (BE, BB, BC): These anonymized categories are historically associated with lower\n",
      "fraud rates.\n",
      "Escalation Rules\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from transformers import logging as transformers_logging\n",
    "transformers_logging.set_verbosity_error()\n",
    "logging.getLogger(\"huggingface_hub\").setLevel(logging.ERROR)\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.tools import tool\n",
    "import chromadb\n",
    "import sys\n",
    "\n",
    "# Fix for SQLite on Mac (common issue with ChromaDB)\n",
    "if sys.platform.startswith('darwin'):\n",
    "    try:\n",
    "        __import__('pysqlite3')\n",
    "        sys.modules['sqlite3'] = sys.modules['pysqlite3']\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "CHROMA_PATH = \"./chroma_db\"\n",
    "CHROMA_COLLECTION_NAME = \"bank_policies\"\n",
    "\n",
    "@tool\n",
    "def search_bank_policy(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Searches the official Bank Anti-Fraud Policy documentation. \n",
    "    Use this tool when you need to verify if a flagged transaction \n",
    "    violates specific banking regulations or internal risk thresholds.\n",
    "    \"\"\"\n",
    "    # Consistency: Use same embeddings and paths as ingestion\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    # Initialize Persistent Client\n",
    "    chroma_client = chromadb.PersistentClient(path=CHROMA_PATH)\n",
    "\n",
    "    vector_db = Chroma(\n",
    "        client=chroma_client,\n",
    "        embedding_function=embeddings,\n",
    "        collection_name=CHROMA_COLLECTION_NAME\n",
    "    )\n",
    "    \n",
    "    # Perform the Similarity Search\n",
    "    # k=1 returns only the single most relevant paragraph\n",
    "    docs = vector_db.similarity_search(query, k=1)\n",
    "    \n",
    "    if not docs:\n",
    "        return \"No relevant policy found for this query.\"\n",
    "    \n",
    "    # Return the text content of the best match\n",
    "    return docs[0].page_content\n",
    "\n",
    "# Test the tool manually\n",
    "try:\n",
    "    # result = search_bank_policy.invoke(\"What is the limit for overseas wire transfers?\")\n",
    "    result = search_bank_policy.invoke(\"housing status\")\n",
    "    print(f\"Policy Found: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during search: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9489bc0",
   "metadata": {},
   "source": [
    "### Testing tools and functions\n",
    "Please comment out @tools from above functions to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ddd8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EEEE\n",
      "======================================================================\n",
      "ERROR: test_get_user_transactions_output_type (__main__.TestCoreTools.test_get_user_transactions_output_type)\n",
      "Verify that get_user_transactions returns a pandas DataFrame.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/j_/r592xntd31b897xl6vt_hhl00000gn/T/ipykernel_59333/3919581003.py\", line 23, in test_get_user_transactions_output_type\n",
      "    df = get_user_transactions(\"USER_0000\")\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: 'StructuredTool' object is not callable\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_get_user_transactions_valid_user (__main__.TestCoreTools.test_get_user_transactions_valid_user)\n",
      "Verify that get_user_transactions returns data for a valid user.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/j_/r592xntd31b897xl6vt_hhl00000gn/T/ipykernel_59333/3919581003.py\", line 32, in test_get_user_transactions_valid_user\n",
      "    df = get_user_transactions(\"USER_0000\")\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: 'StructuredTool' object is not callable\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_search_bank_policy_content (__main__.TestCoreTools.test_search_bank_policy_content)\n",
      "Verify that search_bank_policy returns relevant content.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/j_/r592xntd31b897xl6vt_hhl00000gn/T/ipykernel_59333/3919581003.py\", line 54, in test_search_bank_policy_content\n",
      "    result = search_bank_policy(\"risk indicators\")\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: 'StructuredTool' object is not callable\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_search_bank_policy_output_type (__main__.TestCoreTools.test_search_bank_policy_output_type)\n",
      "Verify that search_bank_policy returns a string.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/j_/r592xntd31b897xl6vt_hhl00000gn/T/ipykernel_59333/3919581003.py\", line 44, in test_search_bank_policy_output_type\n",
      "    result = search_bank_policy(\"housing status\")\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: 'StructuredTool' object is not callable\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.003s\n",
      "\n",
      "FAILED (errors=4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x136ac5010>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "from transformers import logging as transformers_logging\n",
    "transformers_logging.set_verbosity_error()\n",
    "logging.getLogger(\"huggingface_hub\").setLevel(logging.ERROR)\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "import unittest\n",
    "\n",
    "# Fix for SQLite on Mac (common issue with ChromaDB)\n",
    "if sys.platform.startswith('darwin'):\n",
    "    try:\n",
    "        __import__('pysqlite3')\n",
    "        sys.modules['sqlite3'] = sys.modules['pysqlite3']\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "# --- Unit Tests ---\n",
    "class TestCoreTools(unittest.TestCase):\n",
    "    \n",
    "    def test_get_user_transactions_output_type(self):\n",
    "        \"\"\"Verify that get_user_transactions returns a pandas DataFrame.\"\"\"\n",
    "        # Using a sample user ID from the database\n",
    "        df = get_user_transactions(\"USER_0000\")\n",
    "        if df is not None:\n",
    "            self.assertIsInstance(df, pd.DataFrame)\n",
    "            print(\"\\n[PASSED] get_user_transactions returns a DataFrame.\")\n",
    "        else:\n",
    "            self.skipTest(\"Fraud_Agent.db not found for integration test.\")\n",
    "\n",
    "    def test_get_user_transactions_valid_user(self):\n",
    "        \"\"\"Verify that get_user_transactions returns data for a valid user.\"\"\"\n",
    "        df = get_user_transactions(\"USER_0000\")\n",
    "        if df is not None:\n",
    "            # We know USER_0000 exists if the database was setup correctly\n",
    "            # If the DB is empty, this might be 0, but it should still be a DF\n",
    "            self.assertTrue(len(df) >= 0)\n",
    "            print(f\"[PASSED] get_user_transactions returned {len(df)} rows for USER_0000.\")\n",
    "        else:\n",
    "            self.skipTest(\"Fraud_Agent.db not found for integration test.\")\n",
    "\n",
    "    def test_search_bank_policy_output_type(self):\n",
    "        \"\"\"Verify that search_bank_policy returns a string.\"\"\"\n",
    "        if os.path.exists(\"./chroma_db\"):\n",
    "            result = search_bank_policy(\"housing status\")\n",
    "            self.assertIsInstance(result, str)\n",
    "            self.assertNotEqual(result, \"No relevant policy found for this query.\")\n",
    "            print(\"[PASSED] search_bank_policy returns a valid string.\")\n",
    "        else:\n",
    "            self.skipTest(\"./chroma_db not found for integration test.\")\n",
    "\n",
    "    def test_search_bank_policy_content(self):\n",
    "        \"\"\"Verify that search_bank_policy returns relevant content.\"\"\"\n",
    "        if os.path.exists(\"./chroma_db\"):\n",
    "            result = search_bank_policy(\"risk indicators\")\n",
    "            self.assertTrue(len(result) > 10)\n",
    "            print(f\"[PASSED] search_bank_policy returned relevant content: {result[:50]}...\")\n",
    "        else:\n",
    "            self.skipTest(\"./chroma_db not found for integration test.\")\n",
    "\n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58710ff0",
   "metadata": {},
   "source": [
    "## Phase 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shap_agent_bridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saimzafar2002-apple.com/venvs/python_3_12/lib/python3.12/site-packages/sklearn/base.py:463: InconsistentVersionWarning: Trying to unpickle estimator OneHotEncoder from version 1.7.2 when using version 1.8.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/saimzafar2002-apple.com/venvs/python_3_12/lib/python3.12/site-packages/sklearn/base.py:463: InconsistentVersionWarning: Trying to unpickle estimator FunctionTransformer from version 1.7.2 when using version 1.8.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/saimzafar2002-apple.com/venvs/python_3_12/lib/python3.12/site-packages/sklearn/base.py:463: InconsistentVersionWarning: Trying to unpickle estimator ColumnTransformer from version 1.7.2 when using version 1.8.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud Score: 0.026204688474535942\n",
      "Top Reasons: ['velocity_24h = 1900.43', 'income = 0.90', 'velocity_4w = 3114.91']\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import xgboost as xgb\n",
    "\n",
    "# 1. Load Preprocessor and Model\n",
    "preprocessor = joblib.load('preprocessor.joblib')\n",
    "model = xgb.XGBClassifier()\n",
    "model.load_model('XGBoostModel.json')\n",
    "\n",
    "# 2. Get a sample high-risk transaction\n",
    "# We'll use a sample from the dataframe created in Phase 2\n",
    "sample_row = df.iloc[0].to_dict()\n",
    "\n",
    "# 3. Generate SHAP explanation\n",
    "explanation = get_shap_explanation(sample_row, model, preprocessor)\n",
    "print(f\"Fraud Score: {explanation['score']}\")\n",
    "print(f\"Top Reasons: {explanation['top_reasons']}\")\n",
    "\n",
    "# 4. Store user_id for the agent\n",
    "investigated_user_id = sample_row.get('user_id', 'USER_0000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b5306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -qU langchain-google-genai langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f4b2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data read from SQLite table:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 1308.98it/s, Materializing param=pooler.dense.weight]                             \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"\\nInvestigate transaction for USER_0000.\\nModel Fraud Probability: 0.03\\nTop SHAP Contributing Factors:\\n- velocity_24h = 1900.43\\n- income = 0.90\\n- velocity_4w = 3114.91\\n\\nPlease check the user's transaction history and cross-reference with bank policy to generate a final memo.\\n\", additional_kwargs={}, response_metadata={}, id='22073790-cab4-40c8-bf11-e518888107a4'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'search_bank_policy', 'arguments': '{\"query\": \"velocity thresholds for transactions\"}'}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c8b30-d97f-7b52-9c1a-536e3b96b160-0', tool_calls=[{'name': 'get_user_transactions', 'args': {'user_id': 'USER_0000'}, 'id': '09bba941-11dc-4763-a81a-deb9ef118608', 'type': 'tool_call'}, {'name': 'search_bank_policy', 'args': {'query': 'velocity thresholds for transactions'}, 'id': '073a9f87-0b50-4406-b47b-5c32def8cf7f', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 289, 'output_tokens': 44, 'total_tokens': 333, 'input_token_details': {'cache_read': 0}}),\n",
       "  ToolMessage(content='   fraud_bool  income  name_email_similarity  prev_address_months_count  \\\\\\n0           0     0.9               0.334410                         27   \\n1           0     0.9               0.546967                         97   \\n2           0     0.1               0.146472                         -1   \\n3           0     0.3               0.355624                         51   \\n4           0     0.6               0.476843                         -1   \\n\\n   current_address_months_count  customer_age  days_since_request  \\\\\\n0                             8            20            0.016551   \\n1                             9            20            0.000750   \\n2                            15            30            2.653829   \\n3                             0            30            0.006738   \\n4                           154            30            0.032100   \\n\\n   intended_balcon_amount payment_type  zip_count_4w  ...  has_other_cards  \\\\\\n0               39.586449           AA           654  ...                0   \\n1               23.978368           AA           954  ...                1   \\n2               36.678102           AA          1237  ...                0   \\n3               -0.568260           AB           284  ...                0   \\n4               34.177723           AA           847  ...                0   \\n\\n   proposed_credit_limit  foreign_request    source  \\\\\\n0                  200.0                0  INTERNET   \\n1                  200.0                0  INTERNET   \\n2                  200.0                0  INTERNET   \\n3                  200.0                0  INTERNET   \\n4                  500.0                0  INTERNET   \\n\\n   session_length_in_minutes device_os  keep_alive_session  \\\\\\n0                   1.757558     other                   1   \\n1                  19.799801     other                   1   \\n2                   9.634608     linux                   1   \\n3                  14.437039   windows                   0   \\n4                   2.744018   windows                   1   \\n\\n   device_distinct_emails_8w device_fraud_count    user_id  \\n0                          1                  0  USER_0000  \\n1                          1                  0  USER_0000  \\n2                          1                  0  USER_0000  \\n3                          1                  0  USER_0000  \\n4                          1                  0  USER_0000  \\n\\n[5 rows x 32 columns]', name='get_user_transactions', id='65fbfd2e-4b07-4164-855e-c666a0697d4d', tool_call_id='09bba941-11dc-4763-a81a-deb9ef118608'),\n",
       "  ToolMessage(content='Fraud Detection Policy\\nObjective\\nDetect and mitigate application fraud using model-driven risk indicators derived from SVM model\\noutputs.\\nScope\\nApplies to all new credit and card applications processed by the institution.\\nPositive Fraud Signals (Risk Increasing)\\n1. Missing Previous Address Duration: If the number of months in the previous registered address is\\nmissing, this is considered a strong fraud signal. 2. Device Operating System = Windows: Applications\\nsubmitted from Windows devices are considered a moderate fraud signal.\\nNegative Fraud Signals (Risk Reducing)\\n1. Session Persistence on Logout: User keeping session alive is a negative fraud indicator. 2.\\nName–Email Similarity: High similarity between applicant name and email handle reduces fraud\\nlikelihood. 3. Valid Home Phone Number: Validated home phone numbers reduce fraud risk. 4. Existing\\nCards with Same Banking Company: Existing customer relationship is a strong negative fraud signal. 5.', name='search_bank_policy', id='49088bd5-5f6e-48b6-9ea9-0b066b17b64b', tool_call_id='073a9f87-0b50-4406-b47b-5c32def8cf7f'),\n",
       "  AIMessage(content=\"The user's transaction history shows no previous fraud, and the income is high (0.90), which are positive indicators. The bank policy does not specify exact velocity thresholds but generally flags high velocity as a risk. However, the transaction's fraud probability is very low (0.03) and does not appear to violate any explicit policies. Therefore, this transaction is unlikely to be fraudulent.\\n\\nMemo:\\nThis transaction, with a fraud probability of 0.03, shows a low risk score. The user's history indicates no prior fraudulent activity and a high income level, which are positive factors. While the velocity metrics are high, they do not explicitly violate bank policy thresholds, and the overall low probability suggests this is not a fraudulent transaction.\", additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c8b30-e822-7311-af30-cdd7d7b70310-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 1271, 'output_tokens': 156, 'total_tokens': 1427, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.tools import tool \n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Configure your API key\n",
    "load_dotenv(\"GoogleAPI.env\") \n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Prompt\n",
    "Prompt = \"\"\"You are a Senior Fraud Investigator.\n",
    "You will be given a transaction and its SHAP explanations.\n",
    "Use your tools to check the user's history and bank policy.\n",
    "Then, write a 3-sentence memo concluding if it is fraud or not.\"\"\"\n",
    "\n",
    "# 1. Define Tools\n",
    "tools = [get_user_transactions, search_bank_policy]\n",
    "\n",
    "# 2. Initialize the model\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    api_key = GOOGLE_API_KEY,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Initialize the agent\n",
    "agent = create_agent(llm, tools, system_prompt= Prompt)\n",
    "\n",
    "\n",
    "# 4. Run the agent with dynamic query from SHAP\n",
    "reasons_str = \"\\n\".join([f\"- {r}\" for r in explanation['top_reasons']])\n",
    "query = f\"\"\"\n",
    "Investigate transaction for {investigated_user_id}.\n",
    "Model Fraud Probability: {explanation['score']:.2f}\n",
    "Top SHAP Contributing Factors:\n",
    "{reasons_str}\n",
    "\n",
    "Please check the user's transaction history and cross-reference with bank policy to generate a final memo.\n",
    "\"\"\"\n",
    "agent.invoke({\"messages\": [(\"user\", query)]})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.12 (venv)",
   "language": "python",
   "name": "python_3_12_12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1871d15",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41d8df07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, fbeta_score, precision_score, recall_score\n",
    "\n",
    "random_seed = 20888160"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa127cb0",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f025036b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (1.0.0).\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/sgpjesus/bank-account-fraud-dataset-neurips-2022?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 532M/532M [00:08<00:00, 63.1MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/saimzafar2002-apple.com/.cache/kagglehub/datasets/sgpjesus/bank-account-fraud-dataset-neurips-2022/versions/2\n",
      "Size of dataset - 1000000\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"sgpjesus/bank-account-fraud-dataset-neurips-2022\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "# ensure we point to a .csv file (dataset_download may return a path without extension)\n",
    "csv_path = str(path) + \"/Base.csv\"\n",
    "\n",
    "# read the CSV into a DataFrame\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "#print(df.head)\n",
    "size_val = df['fraud_bool'].size\n",
    "print(\"Size of dataset - \" + str(size_val))\n",
    "#print(\"Column Names\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fd763ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full training data # rows: 794989\n",
      "Full test data # rows: 205011\n",
      "Column list: Index(['fraud_bool', 'income', 'name_email_similarity',\n",
      "       'prev_address_months_count', 'current_address_months_count',\n",
      "       'customer_age', 'days_since_request', 'intended_balcon_amount',\n",
      "       'payment_type', 'zip_count_4w', 'velocity_6h', 'velocity_24h',\n",
      "       'velocity_4w', 'bank_branch_count_8w',\n",
      "       'date_of_birth_distinct_emails_4w', 'employment_status',\n",
      "       'credit_risk_score', 'email_is_free', 'housing_status',\n",
      "       'phone_home_valid', 'phone_mobile_valid', 'bank_months_count',\n",
      "       'has_other_cards', 'proposed_credit_limit', 'foreign_request', 'source',\n",
      "       'session_length_in_minutes', 'device_os', 'keep_alive_session',\n",
      "       'device_distinct_emails_8w'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# data processing\n",
    "mask = df[\"month\"] <= 5\n",
    "full_training_data = df[mask].sample(frac=1).reset_index(drop=True).drop('month',axis=1) # train on months 0 to 5. drop month as a feature\n",
    "full_test_data = df[~mask].sample(frac=1).reset_index(drop=True).drop('month',axis=1) # test on months 6 and 7. drop month as a feature\n",
    "\n",
    "# 'device_fraud_count' is literally a constant column. get rid of it.\n",
    "full_training_data = full_training_data.drop('device_fraud_count',axis=1)\n",
    "full_test_data = full_test_data.drop('device_fraud_count',axis=1)\n",
    "\n",
    "print(\"Full training data # rows: \" + str(full_training_data.shape[0]))\n",
    "print(\"Full test data # rows: \" + str(full_test_data.shape[0]))\n",
    "print(\"Column list: \" + str(full_training_data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5503320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['payment_type', 'employment_status', 'housing_status', 'source', 'device_os']\n"
     ]
    }
   ],
   "source": [
    "# more data processing\n",
    "y_train_full = full_training_data[\"fraud_bool\"]\n",
    "X_train_full = full_training_data.drop(\"fraud_bool\",axis=1)\n",
    "y_test_full = full_test_data[\"fraud_bool\"]\n",
    "X_test_full = full_test_data.drop(\"fraud_bool\",axis=1)\n",
    "\n",
    "# make sure all numerical columns are actually stored numerically\n",
    "y_train_full = y_train_full.astype(float)\n",
    "y_test_full = y_test_full.astype(float)\n",
    "for col in X_train_full.columns:\n",
    "    converted = pd.to_numeric(X_train_full[col], errors='coerce')\n",
    "    if converted.notna().sum() == X_train_full[col].notna().sum():\n",
    "        X_train_full[col] = converted\n",
    "for col in X_test_full.columns:\n",
    "    converted = pd.to_numeric(X_test_full[col], errors='coerce')\n",
    "    if converted.notna().sum() == X_test_full[col].notna().sum():\n",
    "        X_test_full[col] = converted\n",
    "\n",
    "categorical_cols = X_train_full.select_dtypes(exclude='number').columns.tolist()\n",
    "print(\"Categorical columns: \" + str(categorical_cols))\n",
    "\n",
    "missing_cols = [\n",
    "    \"prev_address_months_count\",\n",
    "    \"current_address_months_count\",\n",
    "    \"bank_months_count\",\n",
    "    \"session_length_in_minutes\"\n",
    "]\n",
    "\n",
    "# Convert -1 to NaN in both train and test\n",
    "X_train_full[missing_cols] = X_train_full[missing_cols].replace(-1, np.nan)\n",
    "X_test_full[missing_cols] = X_test_full[missing_cols].replace(-1, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "305b03c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(794989, 45)\n",
      "(205011, 45)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# one hot encoding\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "ohe = OneHotEncoder(\n",
    "    drop=\"first\",\n",
    "    handle_unknown=\"ignore\",\n",
    "    sparse_output=False\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[(\"cat\", ohe, categorical_cols)],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "preprocessor.set_output(transform=\"pandas\")\n",
    "\n",
    "X_train_full = preprocessor.fit_transform(X_train_full)\n",
    "X_test_full  = preprocessor.transform(X_test_full)\n",
    "\n",
    "# transform into numpy arrays\n",
    "X_train_full = X_train_full.to_numpy()\n",
    "X_test_full = X_test_full.to_numpy()\n",
    "\n",
    "print(X_train_full.shape)\n",
    "print(X_test_full.shape)\n",
    "\n",
    "print(type(X_train_full))\n",
    "print(type(X_test_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024b6ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.17451520391697056, 4, 2.614887426109477, 0.9485060857785709, 0.7699750549936667, 69.20168627251141), (0.16905821771012308, 5, 2.656553443137637, 0.7536292501403133, 0.9018455006716423, 149.45525912295338), (0.16642979828658203, 6, 7.137705412276479, 0.741225660594348, 0.6188761821681114, 115.07840695382731), (0.03795041745754935, 4, 9.334959888208514, 0.9993629680507733, 0.6852665325348994, 197.5130497055601), (0.10043096967806842, 3, 6.1966714868861, 0.8443053450075143, 0.7360089157716136, 17.380685266385374), (0.07479153485986761, 8, 2.4941799305416206, 0.7655593670035046, 0.9102216553085859, 22.299158482193267), (0.07012870591758696, 7, 2.019503008339158, 0.9112736518539465, 0.6617652366696908, 59.9162649010584), (0.04279856656857445, 3, 3.467406013913698, 0.8697442933303215, 0.8984373361899485, 20.213830100895496), (0.10824452835945124, 5, 1.5440907833681796, 0.7551187188007809, 0.6054313477718477, 14.714304631234496), (0.087545711064077, 6, 4.003929859573627, 0.8986602211528855, 0.6234160533844246, 13.85531505645167), (0.10108389833866423, 5, 2.5603167213938764, 0.9332424238753946, 0.6915085724002867, 38.28188591811754), (0.05090460346833751, 4, 8.101453296609256, 0.7974843177475552, 0.8270509856565389, 49.83975375336611), (0.15334021382665436, 3, 9.982900668182475, 0.7643494137635845, 0.9118668718346394, 13.490239259761912), (0.1494562287634216, 6, 3.133974174961103, 0.7081775635796219, 0.6145831864796502, 10.929831487887183), (0.16261540511515982, 6, 6.0491956989196805, 0.7786913456672153, 0.9409608452817124, 17.91283534805849), (0.14571740991810267, 5, 7.8777513886042625, 0.8215792275563603, 0.6733418208030272, 60.27060897410218), (0.033962383180225826, 3, 7.637642040626277, 0.8143097938777877, 0.661389107588735, 57.750300157555984), (0.03417779687171907, 4, 2.8469847626466316, 0.9640628997444597, 0.8226619101024373, 185.58876009232057), (0.030094224849565573, 8, 2.3397661693782004, 0.9784512583420121, 0.8862500680804013, 75.01539916878734), (0.07845519922936546, 3, 3.344859082845874, 0.9293230510401049, 0.7106983663156454, 13.696664056260941)]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def sample_hyperparams(n_samples=20):\n",
    "\n",
    "    combos = []\n",
    "\n",
    "    for _ in range(n_samples):\n",
    "\n",
    "        # learning_rate: logspace from 0.03 to 0.2 (base 10)\n",
    "        lr_exp = np.random.uniform(np.log10(0.03), np.log10(0.2))\n",
    "        learning_rate = 10 ** lr_exp\n",
    "\n",
    "        # max_depth: integer uniform in [3,8]\n",
    "        max_depth = np.random.randint(3, 9)\n",
    "\n",
    "        # min_child_weight: uniform in [1,10]\n",
    "        min_child_weight = np.random.uniform(1, 10)\n",
    "\n",
    "        # subsample: uniform in [0.7,1.0]\n",
    "        subsample = np.random.uniform(0.7, 1.0)\n",
    "\n",
    "        # colsample_bytree: uniform in [0.6,1.0]\n",
    "        colsample_bytree = np.random.uniform(0.6, 1.0)\n",
    "\n",
    "        # scale_pos_weight: logspace from 10 to 200 (base 10)\n",
    "        spw_exp = np.random.uniform(np.log10(10), np.log10(200))\n",
    "        scale_pos_weight = 10 ** spw_exp\n",
    "\n",
    "        combos.append((learning_rate, max_depth, min_child_weight, subsample, colsample_bytree, scale_pos_weight))\n",
    "\n",
    "    return combos\n",
    "\n",
    "n_hypers = 20\n",
    "hyperparameter_combinations = sample_hyperparams(n_hypers)\n",
    "print(hyperparameter_combinations)\n",
    "\n",
    "# threshold candidates: 25 values from 0 to 1\n",
    "thresholds = np.linspace(0.0, 1.0, 25)\n",
    "\n",
    "full_hyperparameter_combinations = [hyper + (threshold,) for hyper in hyperparameter_combinations for threshold in thresholds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2341b878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import fbeta_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# train the final model\n",
    "\n",
    "learning_rate, max_depth, min_child_weight, subsample, colsample_bytree, scale_pos_weight, best_threshold = (0.06171184631285087, 3, 9.400860129136118, 0.7741235778036006, 0.7017163522086355, 10.92551522008694, 0.375)\n",
    "best_iteration_int = 540\n",
    "\n",
    "# Use XGBClassifier for Scikit-Learn compatibility\n",
    "XGB_model = xgb.XGBClassifier(\n",
    "    learning_rate=learning_rate,\n",
    "    max_depth=max_depth,\n",
    "    min_child_weight=min_child_weight,\n",
    "    subsample=subsample,\n",
    "    colsample_bytree=colsample_bytree,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"aucpr\",\n",
    "    tree_method=\"hist\",\n",
    "    verbosity=0,\n",
    "    n_estimators=best_iteration_int,\n",
    "    use_label_encoder=False\n",
    ")\n",
    "XGB_model.fit(X_train_full, y_train_full)\n",
    "# predict_proba returns [prob_class_0, prob_class_1]\n",
    "y_test_prob = XGB_model.predict_proba(X_test_full)[:, 1]\n",
    "y_test_pred = (y_test_prob >= best_threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aca0cf",
   "metadata": {},
   "source": [
    "# Export to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9ff691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Example: get parameters from a scikit-learn model\n",
    "model_params = XGB_model.get_params() \n",
    "filename = 'XGBoostModelParameters.json'\n",
    "\n",
    "# Save parameters to a JSON file\n",
    "with open(filename, 'w') as file:\n",
    "    json.dump(model_params, file, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
